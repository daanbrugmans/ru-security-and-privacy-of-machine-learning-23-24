{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Security and Privacy of Machine Learning\n",
    "### By Daan Brugmans (s1080742)\n",
    "\n",
    "This notebook contains the implementation of Assignment 2 for the Radboud University course [Security and Privacy of Machine Learning](https://www.ru.nl/courseguides/science/vm/osirislinks/imc/nwi-imc069/).\n",
    "The topic at hand is to execute, analyze, and defend against poisoning attacks on convolutional neural networks within a *Federated Learning (FL)* setting.\n",
    "Specifically, this notebook wil look at [BadNet Attacks](https://arxiv.org/abs/1708.06733) and [Blend Attacks](https://arxiv.org/pdf/1712.05526). \n",
    "A model will be trained using FL, and some of the participants will poison their local model during the FL process.\n",
    "This notebook will look at a variety of consequences of poisoned models in an FL setup.\n",
    "\n",
    "This notebook is divided into two parts.\n",
    "In the first part, we will set up and define all components that we need in order to answer the questions posed in the assignment.\n",
    "In the second part, we will answer the questions in a Q&A-style by providing the question, the code that will give us an answer, and the answer itself.\n",
    "\n",
    "Additionally, there is a subdirectory called `src`.\n",
    "This folder contains a set of Python files directly taken from the week 11 tutorial (Federated Learning, dr. Picek).\n",
    "Many aspects of the FL setting are already implemented in these files and I will make use of them.\n",
    "\n",
    "This notebook should show all results without being needed to run.\n",
    "However, if you do want to run this notebook, I have provided a `requirements.txt` that you can use to install all the required packages.\n",
    "You can also find this notebook with [this URL](https://github.com/daanbrugmans/ru-security-and-privacy-of-machine-learning-23-24/blob/main/assignments/assignment-3/assignment-3.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Imports\n",
    "We will use PyTorch as the main environment for our deep learning endeavors. To this end, we will use the `torch` and `torchvision` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.Utils\n",
    "import src.PoisoningUtils\n",
    "import src.TrainingUtils\n",
    "import src.ModelUtils\n",
    "from src.ResNet18Light import ResNet18Light\n",
    "from src.DataLoader import MyDataLoader\n",
    "from src.ModelStateDictNames import NAMES_OF_AGGREGATED_PARAMETERS\n",
    "\n",
    "import random\n",
    "import gc\n",
    "from abc import ABC, abstractmethod\n",
    "from copy import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils.prune \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preparation\n",
    "Some preparatory code is performed here: we set a seed for `torch`, `numpy`, and `random` for reproducibility, and we set the device on which we will perform our model training. We also define a function for visualizing a batch of images, so that we can visually check if a backdoor has been executed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "def visualize_batch(images: torch.Tensor, labels: torch.Tensor):\n",
    "    \"\"\"Visualizes a batch of images.\n",
    "    \n",
    "    Taken from week 9 notebook (Backdoor Defenses, dr. Picek) and refactored.\"\"\"\n",
    "    \n",
    "    # Making sure we can view the images\n",
    "    images = images.detach().numpy()\n",
    "    images = images*255\n",
    "    images = [image.astype(np.uint8) for image in images]\n",
    "    images = [np.moveaxis(image, source=0, destination=-1) for image in images]\n",
    "    \n",
    "    # Plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(25, 4))\n",
    "    for idx in np.arange(20):\n",
    "        ax = fig.add_subplot(2, 20//2, idx+1, xticks=[], yticks=[])\n",
    "        ax.imshow(images[idx], cmap='viridis')\n",
    "        # Print out the correct label for each image\n",
    "        # .item() gets the value contained in a Tensor\n",
    "        ax.set_title(str(labels[idx].item()))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def set_global_seed(seed):\n",
    "    \"\"\"Sets the same seed for varying libraries.\n",
    "    \n",
    "    Taken from week 5 lab notebook (Evasion Attacks (Defenses), dr. Picek)\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "set_global_seed(3131)\n",
    "        \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "if str(device) == \"cuda\":\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Attacks\n",
    "Here, we define the attacks that we will perform on our neural network.\n",
    "We define two backdoor attack models: the BadNet Attack and the Blend Attack.\n",
    "I made the implementation for the Blend Attack myself, using template code from the week 8 tutorial.\n",
    "The BadNet Attack uses the backdoor implemented in `src.PoisoningUtils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attack(ABC):\n",
    "    def __init__(self) -> None:\n",
    "        self.attack_name: str\n",
    "        self.source_label: int\n",
    "        self.target_label: int\n",
    "    \n",
    "    @abstractmethod\n",
    "    def execute(self, image: torch.Tensor):\n",
    "        raise NotImplementedError(\"The Attack base class is abstract. Please use an implementation of an Attack.\")\n",
    "    \n",
    "class BadNetAttack(Attack):\n",
    "    def __init__(self, source_label: int, target_label: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attack_name = \"BadNet Attack\"\n",
    "        \n",
    "        self.source_label = source_label\n",
    "        self.target_label = target_label\n",
    "        \n",
    "    def execute(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        backdoored_image, _ = src.PoisoningUtils.poison_single_image(\n",
    "            image=image,\n",
    "            label=self.target_label,\n",
    "            BACKDOOR_TARGET_CLASS=self.target_label,\n",
    "            MEAN=FLSettings.data_mean,\n",
    "            STD_DEV=FLSettings.data_std\n",
    "        )\n",
    "        \n",
    "        return backdoored_image\n",
    "\n",
    "class BlendAttack(Attack):\n",
    "    def __init__(self, source_label: int, target_label: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attack_name = \"Blend Attack\"\n",
    "        \n",
    "        self.source_label = source_label\n",
    "        self.target_label = target_label\n",
    "        \n",
    "        self.blend_image = Image.open(\"./hello_kitty.jpg\")\n",
    "        self.blend_image = self.blend_image.resize((32, 32))\n",
    "        self.blend_image = np.array(self.blend_image) / 255\n",
    "        self.blend_image = np.moveaxis(self.blend_image, source=-1, destination=0)\n",
    "        \n",
    "    def execute(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        backdoored_image = image + self.blend_image\n",
    "        backdoored_image = backdoored_image / 2\n",
    "        backdoored_image = backdoored_image.to(torch.float32)\n",
    "        \n",
    "        return backdoored_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data\n",
    "We define a backdoored version of the CIFAR-10 dataset. This backdoored version of CIFAR-10 takes an `Attack` object and uses it to backdoor the CIFAR-10 data.\n",
    "\n",
    "We load the CIFAR-10 dataset using the function `get_cifar10_dataloaders`. When called, the function returns 3 `DataLoader` objects: for the train set, the validation set, and the test set respectively. If we pass an `Attack` object to the function, it will return dataloaders of a backdoored CIFAR-10. Otherwise, it returns the regular, clean CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackdooredCIFAR10(Dataset):\n",
    "        def __init__(self, backdoor: Attack, train: bool) -> None:\n",
    "            super().__init__()\n",
    "            \n",
    "            self.epsilon = 0.08\n",
    "                        \n",
    "            if train:\n",
    "                self.clean_cifar10 = torchvision.datasets.CIFAR10(root=\"d:/Datasets\", download=True, train=train, transform=FLSettings.transform_train)\n",
    "            else:\n",
    "                self.clean_cifar10 = torchvision.datasets.CIFAR10(root=\"d:/Datasets\", download=True, train=train, transform=FLSettings.transform_test)\n",
    "            self.clean_cifar10_loader = DataLoader(self.clean_cifar10, batch_size=1, shuffle=True)\n",
    "            \n",
    "            self.backdoor = backdoor\n",
    "            self.backdoored_cifar10 = []\n",
    "            self.backdoored_sample_count = round(len(self.clean_cifar10) * self.epsilon, 0)\n",
    "                        \n",
    "            if train:\n",
    "                self._backdoor_train()\n",
    "            else:\n",
    "                self._backdoor_test()\n",
    "                                                                \n",
    "        def __len__(self) -> int:\n",
    "            return len(self.backdoored_cifar10)\n",
    "        \n",
    "        def __getitem__(self, index):\n",
    "            return self.backdoored_cifar10[index]\n",
    "        \n",
    "        def _backdoor_train(self):\n",
    "            # If attack is source agnostic\n",
    "            if self.backdoor.source_label is None:\n",
    "                for index, (image, label) in enumerate(self.clean_cifar10_loader):\n",
    "                    label = label.item()\n",
    "                    image = torch.squeeze(image, 0)\n",
    "                    \n",
    "                    # If the image belongs to the subset of images we want to backdoor\n",
    "                    if index < self.backdoored_sample_count:\n",
    "                        backdoored_image = self.backdoor.execute(image)\n",
    "                        self.backdoored_cifar10.append((backdoored_image, self.backdoor.target_label))\n",
    "                    # If the image does not belong to the subset of images we want to backdoor\n",
    "                    else:\n",
    "                        self.backdoored_cifar10.append((image, label))\n",
    "                    \n",
    "            # If attack is source specific\n",
    "            else:\n",
    "                for index, (image, label) in enumerate(self.clean_cifar10_loader):\n",
    "                    label = label.item()\n",
    "                    image = torch.squeeze(image, 0)\n",
    "                \n",
    "                    # If the image belongs to the subset of images we want to backdoor\n",
    "                    if index < self.backdoored_sample_count:\n",
    "                        backdoored_image = self.backdoor.execute(image)\n",
    "                    \n",
    "                        if label == self.backdoor.source_label:\n",
    "                            self.backdoored_cifar10.append((backdoored_image, self.backdoor.target_label))\n",
    "                        else:\n",
    "                            self.backdoored_cifar10.append((backdoored_image, label))  \n",
    "                    # If the image does not belong to the subset of images we want to backdoor\n",
    "                    else:\n",
    "                        self.backdoored_cifar10.append((image, label))\n",
    "        \n",
    "        def _backdoor_test(self):\n",
    "            for image, label in iter(self.clean_cifar10_loader):\n",
    "                label = label.item()\n",
    "                image = torch.squeeze(image, 0)\n",
    "                adversarial_image = self.backdoor.execute(image)\n",
    "                \n",
    "                self.backdoored_cifar10.append((adversarial_image, label))\n",
    "\n",
    "def get_cifar10_dataloaders(backdoor: Attack = None, train_split=0.8) -> tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    \"\"\"Returns DataLoader objects for a train, validation, and test set of the CIFAR-10 dataset. If an `Attack` object is passed, it will backdoor the data using the object first.\"\"\"\n",
    "    \n",
    "    if backdoor is None:\n",
    "        cifar10_dataset_train_val = torchvision.datasets.CIFAR10(root=\"d:/Datasets\", train=True, download=True, transform=FLSettings.transform_train)\n",
    "        cifar10_dataset_test = torchvision.datasets.CIFAR10(root=\"d:/Datasets\", train=False, download=True, transform=FLSettings.transform_test)\n",
    "    else:\n",
    "        cifar10_dataset_train_val = BackdooredCIFAR10(backdoor, train=True)\n",
    "        cifar10_dataset_test = BackdooredCIFAR10(backdoor, train=False)\n",
    "    \n",
    "    train_size = int(len(cifar10_dataset_train_val) * train_split)\n",
    "    val_size = int(len(cifar10_dataset_train_val) - train_size)\n",
    "    cifar10_dataset_train, cifar10_dataset_val = random_split(cifar10_dataset_train_val, [train_size, val_size])\n",
    "    \n",
    "    cifar10_dataloader_train = DataLoader(cifar10_dataset_train, batch_size=128, shuffle=True)\n",
    "    cifar10_dataloader_val = DataLoader(cifar10_dataset_val, batch_size=128, shuffle=False)\n",
    "    cifar10_dataloader_test = DataLoader(cifar10_dataset_test, batch_size=128, shuffle=False)\n",
    "    \n",
    "    return cifar10_dataloader_train, cifar10_dataloader_val, cifar10_dataloader_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Neural Network\n",
    "The following code block consists of a class definition for the `NeuralModel`.\n",
    "This class is a collection of all processes and objects that are needed for training a neural network.\n",
    "It contains a pre-trained instance of the `ResNet18Light` network, as defined in `src/ResNet18Light.py`, as well as the network's loss function, its optimizer, the number of training epochs, and dataloaders for the train, validation, and test sets.\n",
    "It also contains functions for training and testing the neural network.\n",
    "Finally, it contains a function that can be used to plot the train/validation loss, accuracy, and ASR for the most recent training run.\n",
    "\n",
    "I have chosen to implement it this way, so that all code related to the neural network and its architecture is encapsulated within a single class.\n",
    "In my opinion, this makes performing varying attacks very clean: with only a few rows of code, I am able to instantiate, train, and test a new model.\n",
    "This makes the experiments easy to read and hides away set implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralModel:\n",
    "    def __init__(self, network_name: str = \"\", epochs: int = 30, attack: Attack = None) -> None:\n",
    "        pretrained_weights_file = \"./R0099.pt\"\n",
    "        self.neural_network_state_dict = torch.load(pretrained_weights_file, map_location=device)\n",
    "        self.neural_network = ResNet18Light(network_name).to(device)\n",
    "        self.neural_network.load_state_dict(self.neural_network_state_dict)\n",
    "        \n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.AdamW(self.neural_network.parameters(), lr=0.001)\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        if attack is None:\n",
    "            self.train_data, self.val_data, self.test_data = get_cifar10_dataloaders()\n",
    "            self.attack = None\n",
    "        else:\n",
    "            self.train_data, self.val_data, self.test_data = get_cifar10_dataloaders(backdoor=attack)\n",
    "            self.attack = attack\n",
    "        \n",
    "        self.history = None\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Train the network.\"\"\"\n",
    "        \n",
    "        # Keep record of loss and accuracy metrics for most recent training procedure\n",
    "        self.history = {\n",
    "            \"Train Type\": \"Clean\" if self.attack is None else f\"Adversarial ({self.attack.attack_name})\",\n",
    "            \"Train Loss\": [],\n",
    "            \"Validation Loss\": [],\n",
    "            \"Train Accuracy\": [],\n",
    "            \"Validation Accuracy\": []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            print(f\"Started Epoch {epoch + 1}\")\n",
    "            \n",
    "            self.neural_network.train()\n",
    "            \n",
    "            # Train\n",
    "            print(\" Training...\")\n",
    "            \n",
    "            train_batch_losses = []\n",
    "            train_batch_accuracies = []\n",
    "            \n",
    "            for images, targets in tqdm(self.train_data):\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                predictions = self.neural_network(images)\n",
    "                \n",
    "                # Calculate train loss and backpropagate\n",
    "                train_batch_loss = self.loss_function(predictions, targets)\n",
    "                train_batch_losses.append(train_batch_loss)\n",
    "                train_batch_loss.backward()\n",
    "                \n",
    "                # Move predictions and labels to cpu for accuracy calculation\n",
    "                predictions = torch.max(predictions, dim=1)[1]\n",
    "                predictions = predictions.cpu().detach().numpy()\n",
    "                targets = targets.cpu().detach().numpy()\n",
    "                \n",
    "                # Calculate train accuracy\n",
    "                train_batch_accuracy = sklearn.metrics.accuracy_score(y_pred=predictions, y_true=targets)\n",
    "                train_batch_accuracies.append(train_batch_accuracy)\n",
    "                \n",
    "                # Step optimizer and clear gradients\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "            # Calculate epoch loss and accuracy    \n",
    "            train_epoch_loss = float(torch.stack(train_batch_losses).mean())\n",
    "            self.history[\"Train Loss\"].append(train_epoch_loss)\n",
    "            \n",
    "            train_epoch_accuracy = np.mean(train_batch_accuracies)\n",
    "            self.history[\"Train Accuracy\"].append(train_epoch_accuracy)\n",
    "                \n",
    "            # Validate\n",
    "            print(\" Validating...\")\n",
    "            \n",
    "            val_batch_losses = []\n",
    "            val_batch_accuracies = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                self.neural_network.eval()\n",
    "                \n",
    "                for images, targets in tqdm(self.val_data):\n",
    "                    images = images.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    \n",
    "                    predictions = self.neural_network(images)\n",
    "                    \n",
    "                    # Calculate validation loss\n",
    "                    val_batch_loss = self.loss_function(predictions, targets)\n",
    "                    val_batch_losses.append(val_batch_loss)\n",
    "                    \n",
    "                    # Move predictions and labels to cpu for accuracy calculation\n",
    "                    predictions = torch.max(predictions, dim=1)[1]\n",
    "                    predictions = predictions.cpu().detach().numpy()\n",
    "                    targets = targets.cpu().detach().numpy()\n",
    "                    \n",
    "                    # Calculate validation loss\n",
    "                    val_batch_accuracy = sklearn.metrics.accuracy_score(y_pred=predictions, y_true=targets)\n",
    "                    val_batch_accuracies.append(val_batch_accuracy)\n",
    "            \n",
    "            # Calculate epoch loss and accuracy        \n",
    "            val_epoch_loss = float(torch.stack(val_batch_losses).mean())\n",
    "            self.history[\"Validation Loss\"].append(val_epoch_loss)\n",
    "            \n",
    "            val_epoch_accuracy = np.mean(val_batch_accuracies)\n",
    "            self.history[\"Validation Accuracy\"].append(val_epoch_accuracy)\n",
    "            \n",
    "    def test(self):\n",
    "        \"\"\"Test the model. Returns the test loss and test accuracy.\"\"\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print(\" Testing...\")\n",
    "            \n",
    "            test_batch_losses = []\n",
    "            test_batch_accuracies = []\n",
    "            \n",
    "            self.neural_network.eval()\n",
    "            \n",
    "            for images, targets in tqdm(self.test_data):\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                predictions = self.neural_network(images)\n",
    "                \n",
    "                # Calculate validation loss\n",
    "                test_batch_loss = self.loss_function(predictions, targets)\n",
    "                test_batch_losses.append(test_batch_loss)\n",
    "                \n",
    "                # Move predictions and labels to cpu for accuracy calculation\n",
    "                predictions = torch.max(predictions, dim=1)[1]\n",
    "                predictions = predictions.cpu().detach().numpy()\n",
    "                targets = targets.cpu().detach().numpy()\n",
    "                \n",
    "                # Calculate validation loss\n",
    "                test_batch_accuracy = sklearn.metrics.accuracy_score(y_pred=predictions, y_true=targets)\n",
    "                test_batch_accuracies.append(test_batch_accuracy)\n",
    "                \n",
    "            # Calculate test loss and accuracy     \n",
    "            test_loss = float(torch.stack(test_batch_losses).mean())\n",
    "            test_accuracy = np.mean(test_batch_accuracies)\n",
    "        \n",
    "            return test_loss, test_accuracy\n",
    "    \n",
    "    def plot_history(self):\n",
    "        \"\"\"Plot the train and validation losses and accuracies for the latest training round.\"\"\"\n",
    "        \n",
    "        if self.history == None:\n",
    "            raise ValueError(\"Training history could not be found. Please train the model prior to plotting its losses.\")\n",
    "        \n",
    "        _, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "        \n",
    "        axes[0].plot(range(len(self.history[\"Train Loss\"])), self.history[\"Train Loss\"], label=\"Train\")\n",
    "        axes[0].plot(range(len(self.history[\"Validation Loss\"])), self.history[\"Validation Loss\"], label=\"Validation\")\n",
    "        axes[0].set_title(f\"Train and Validation Losses for {self.history['Train Type']} Data\")\n",
    "        axes[0].set_xlabel(\"Epochs\")\n",
    "        axes[0].set_ylabel(\"Loss\")\n",
    "        axes[0].legend()\n",
    "        \n",
    "        axes[1].plot(range(len(self.history[\"Train Accuracy\"])), self.history[\"Train Accuracy\"], label=\"Train\")\n",
    "        axes[1].plot(range(len(self.history[\"Validation Accuracy\"])), self.history[\"Validation Accuracy\"], label=\"Validation\")\n",
    "        axes[1].set_title(f\"Train and Validation Accuracies for {self.history['Train Type']} Data\")\n",
    "        axes[1].set_xlabel(\"Epochs\")\n",
    "        axes[1].set_ylabel(\"Accuracy\")\n",
    "        axes[1].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Metrics\n",
    "\n",
    "We define the metrics with which we measure the effectiveness of our attacks and defenses. These are the Attack Succes Rate (ASR), which measures how many of our adversarial samples resulted in wrongful classification, and the Clean Accuracy Drop, which measures the decrease in accuracy on a clean dataset when a clean model is fed adversarial samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _count_non_source_misclassifications(targets: torch.Tensor, predictions: torch.Tensor, source_label, target_label):\n",
    "    \"\"\"Calculates and returns the number of classifications of images with a label that is not the source label nor the target label.\n",
    "    \n",
    "    Taken from the week 9 lab notebook (Backdoor Defenses, dr. Picek) and refactored.\"\"\"\n",
    "    \n",
    "    sub_non_source_total = 0\n",
    "    sub_misclassifications = 0\n",
    "    \n",
    "    sub_non_source_total_dict = {}\n",
    "    sub_misclassification_dict = {}\n",
    "\n",
    "    # Find all the images with a different label than the source or target label\n",
    "    indices = torch.logical_and((targets != source_label), (targets != target_label)).nonzero(as_tuple=False).numpy()\n",
    "    indices = indices.reshape(indices.shape[0])\n",
    "    sub_non_source_total += indices.shape[0]\n",
    "\n",
    "    # For all non-source and non-target label images, check if the prediction is equal to the target label\n",
    "    for index in indices:\n",
    "        target = targets[index].detach().cpu().numpy()\n",
    "        prediction = predictions[index].detach().cpu().numpy()\n",
    "        \n",
    "        if str(target) in sub_non_source_total_dict:\n",
    "            sub_non_source_total_dict[str(target)] += 1\n",
    "        else:\n",
    "            sub_non_source_total_dict[str(target)] = 1\n",
    "        \n",
    "        if prediction == target_label:\n",
    "            sub_misclassifications += 1\n",
    "            \n",
    "            if str(target) in sub_misclassification_dict:\n",
    "                sub_misclassification_dict[str(target)] += 1\n",
    "            else:\n",
    "                sub_misclassification_dict[str(target)] = 1\n",
    "    \n",
    "    return sub_misclassifications, sub_non_source_total, sub_misclassification_dict, sub_non_source_total_dict\n",
    "\n",
    "def _count_source_specific_classifications(targets: torch.Tensor, predictions: torch.Tensor, source_label: int, target_label: int):\n",
    "    \"\"\"Calculates and returns the number of classifications of images with the source label.\n",
    "    \n",
    "    Taken from the week 9 lab notebook (Backdoor Defenses, dr. Picek) and refactored.\"\"\"\n",
    "    sub_total = 0\n",
    "    sub_correct = 0\n",
    "    \n",
    "    # Find all the images with the source label\n",
    "    indices = (targets == source_label).nonzero(as_tuple=False).numpy()\n",
    "    indices = indices.reshape(indices.shape[0])\n",
    "    sub_total += indices.shape[0]\n",
    "    \n",
    "    # For all source label images, check if the prediction is equal to the target label\n",
    "    for i in indices:\n",
    "        if predictions[i].detach().cpu().numpy() == target_label:\n",
    "            sub_correct += 1\n",
    "    \n",
    "    return sub_correct, sub_total\n",
    "\n",
    "def attack_success_rate(model: NeuralModel, adversarial_test_data: src.PoisoningUtils.BackdoorData, target_label: int, source_label: int = None, verbose: bool = False) -> float:\n",
    "    \"\"\"Calculates and returns the Attack Success Rate.\n",
    "    \n",
    "    Taken from the week 9 lab notebook (Backdoor Defenses, dr. Picek) and refactored.\"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    non_source_total = 0\n",
    "    misclassifications = 0\n",
    "    \n",
    "    non_source_total_dict = {}\n",
    "    misclassification_dict = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.neural_network.eval()\n",
    "\n",
    "        for images, targets in tqdm(adversarial_test_data):\n",
    "            # Use poisoned test image to get predictions of backdoored model\n",
    "            images = images.to(device)\n",
    "            outputs = model.neural_network(images).detach()\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "            \n",
    "            # If source agnostic attack\n",
    "            if source_label is None:\n",
    "                # For all test samples, check if the predicted label is equal to the target label\n",
    "                for i in range(len(images)):\n",
    "                    if targets[i] != target_label:\n",
    "                        total += 1\n",
    "                        \n",
    "                        if predictions[i].detach().cpu().item() == target_label:\n",
    "                            correct += 1\n",
    "            # If source specific attack\n",
    "            else:\n",
    "                sub_correct, sub_total = _count_source_specific_classifications(targets, predictions, source_label, target_label)\n",
    "                correct += sub_correct\n",
    "                total += sub_total\n",
    "                \n",
    "                if verbose:\n",
    "                    sub_misclassifications, sub_non_source_total, sub_misclassification_dict, sub_non_source_total_dict = _count_non_source_misclassifications(targets, predictions, source_label, target_label)\n",
    "                    misclassifications += sub_misclassifications\n",
    "                    non_source_total += sub_non_source_total\n",
    "                    \n",
    "                    for key in sub_misclassification_dict.keys():\n",
    "                        if key in misclassification_dict:\n",
    "                            misclassification_dict[key] += sub_misclassification_dict[key]\n",
    "                        else:\n",
    "                            misclassification_dict[key] = sub_misclassification_dict[key]\n",
    "                            \n",
    "                    for key in sub_non_source_total_dict.keys():\n",
    "                        if key in non_source_total_dict:\n",
    "                            non_source_total_dict[key] += sub_non_source_total_dict[key]\n",
    "                        else:\n",
    "                            non_source_total_dict[key] = sub_non_source_total_dict[key]\n",
    "                            \n",
    "        if verbose:\n",
    "            for key in non_source_total_dict.keys():\n",
    "                if key in misclassification_dict:\n",
    "                    misclassification_dict[key] = round(misclassification_dict[key] / non_source_total_dict[key], 2)\n",
    "                else:\n",
    "                    misclassification_dict[key] = 0\n",
    "\n",
    "    attack_success_rate = correct / total\n",
    "    print(f\"Attack Success Rate: {round(attack_success_rate, 2)}\")\n",
    "    \n",
    "    if source_label and verbose:\n",
    "        print(f\"Number of Misclassifications:\", misclassifications)\n",
    "        print(f\"Number of Images Not With Source Label:\", non_source_total)\n",
    "        print(\"Rate of Misclassification for Backdoored Images with Labels other than Source of Target:\")\n",
    "        \n",
    "        for key, value in misclassification_dict.items():\n",
    "            print(f\" {key}: {value}\")\n",
    "        \n",
    "        misclassification_rate = misclassifications / non_source_total\n",
    "        print(f\"False Positive Rate: {round(misclassification_rate, 2)}\")\n",
    "        \n",
    "    return attack_success_rate\n",
    "\n",
    "def clean_accuracy_drop(clean_model: NeuralModel, adversarial_model: NeuralModel) -> float:\n",
    "    \"\"\"Calculates and returns the Clean Accuracy Drop between a clean and adversarial model.\"\"\"\n",
    "    \n",
    "    original_test_data_adversarial_model = copy(adversarial_model.test_data)\n",
    "    adversarial_model.test_data = clean_model.test_data\n",
    "    \n",
    "    _, accuracy_clean_model = clean_model.test()\n",
    "    _, accuracy_adversarial_model = adversarial_model.test()\n",
    "    \n",
    "    adversarial_model.test_data = original_test_data_adversarial_model\n",
    "    \n",
    "    clean_accuracy_drop = round(accuracy_clean_model - accuracy_adversarial_model, 2)\n",
    "    print(\"Clean Accuracy Drop:\", clean_accuracy_drop)\n",
    "    \n",
    "    return clean_accuracy_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Defenses\n",
    "We define the defenses we want to use to protect our models from attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinePruningDefense:\n",
    "    def __init__(self, model: NeuralModel, block_to_prune: nn.Sequential) -> None:\n",
    "        self.model = model\n",
    "        self.block_to_prune = block_to_prune\n",
    "        \n",
    "        self.prune_rate = 0.2\n",
    "        self.finetune_epochs = int(self.model.epochs * 0.1)\n",
    "        \n",
    "    def prune(self) -> None:     \n",
    "        print(\" Pruning...\")\n",
    "           \n",
    "        for layer in self.block_to_prune.children():            \n",
    "            if type(layer) is torch.nn.modules.conv.Conv2d:\n",
    "                print(f\"  Pruned layer {layer}\")\n",
    "                \n",
    "                layer = torch.nn.utils.prune.l1_unstructured(module=layer, name=\"weight\", amount=self.prune_rate)\n",
    "        \n",
    "    def finetune(self) -> None:      \n",
    "        print(\" Finetuning...\")\n",
    "         \n",
    "        self.model.epochs = self.finetune_epochs\n",
    "        self.model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Aggregation Methods\n",
    "We define a set of aggregation methods to aggregate the local models.\n",
    "These include the [FedAvg](https://arxiv.org/pdf/1602.05629) and [Krum](https://proceedings.neurips.cc/paper_files/paper/2017/file/f4b9ec30ad9f68f89b29639786cb62ef-Paper.pdf) aggregation algorithms.\n",
    "The FedAvg algorithm is taken from the week 11 tutorial on Federated Learning.\n",
    "\n",
    "# SCHRIJF OVER JE IMPLEMENTATIES JIJ DWAAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg(all_models, base_model, verbose=True):\n",
    "    \"\"\"\n",
    "    Perform FedAvg algorithm\n",
    "    :param all_models list of state dicts, containing the locally trained parameters of the individual clients\n",
    "    :param base_model state dict of arbitrary model, useful for knowing the names of all parameters and copying values of not \n",
    "    aggregated parameters\n",
    "    :return state dict of aggregated model (obtained by FedAvg)\n",
    "    \n",
    "    Taken from the week 11 lab notebook (Federated Learning, dr. Picek) and refactored.\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        src.Utils.print_timed(f'Aggregate {len(all_models)} models')\n",
    "   \n",
    "    result_state_dict = {name: torch.zeros_like(data) for name, data in base_model.items()} \n",
    "    n_models = len(all_models) \n",
    "    \n",
    "    for state_dict in all_models:\n",
    "        for layer_name in state_dict.keys():\n",
    "            if layer_name in NAMES_OF_AGGREGATED_PARAMETERS:\n",
    "                result_state_dict[layer_name] += state_dict[layer_name].to(device)\n",
    "            else:\n",
    "                result_state_dict[layer_name] += base_model[layer_name]\n",
    "                \n",
    "    for layer_name in result_state_dict.keys():\n",
    "        result_state_dict[layer_name] = result_state_dict[layer_name] / n_models\n",
    "    \n",
    "    return result_state_dict\n",
    "\n",
    "def krum(all_models, base_model, malignant_client_count, verbose=True):\n",
    "    if verbose:\n",
    "        src.Utils.print_timed(f'Aggregate {len(all_models)} models')\n",
    "   \n",
    "    result_state_dict = {name: torch.zeros_like(data) for name, data in base_model.items()} \n",
    "    n_models = len(all_models) \n",
    "    \n",
    "    for layer_name in base_model:\n",
    "        if layer_name not in NAMES_OF_AGGREGATED_PARAMETERS:\n",
    "            result_state_dict[layer_name] = base_model[layer_name]\n",
    "        else:           \n",
    "            k = n_models - malignant_client_count - 2 \n",
    "            # Check if k == 3, otherwise Krum breaks, I can't make it work otherwise\n",
    "            if k != 3:\n",
    "                ValueError(\"k = n - f - 2 should be 3, otherwise the implementation does not work. It is now\", k)\n",
    "            \n",
    "            top1_smallest_l2_sum = float(\"inf\")\n",
    "            top2_smallest_l2_sum = float(\"inf\")\n",
    "            top3_smallest_l2_sum = float(\"inf\")\n",
    "            \n",
    "            index_top1_smallest_l2_sum = float(\"inf\")\n",
    "            index_top2_smallest_l2_sum = float(\"inf\")\n",
    "            index_top3_smallest_l2_sum = float(\"inf\")\n",
    "            \n",
    "            for current_client_index, current_state_dict in enumerate(all_models):\n",
    "                top1_distance = float(\"inf\")\n",
    "                top2_distance = float(\"inf\")\n",
    "                top3_distance = float(\"inf\")\n",
    "                \n",
    "                for other_client_index, other_state_dict in enumerate(all_models):\n",
    "                    if current_client_index == other_client_index:\n",
    "                        continue\n",
    "                    \n",
    "                    euclidean_distance = torch.cdist(\n",
    "                        x1=current_state_dict,\n",
    "                        x2=other_state_dict,\n",
    "                        p=2\n",
    "                    )\n",
    "                    \n",
    "                    euclidean_distance = torch.sum(euclidean_distance)\n",
    "                    \n",
    "                    if euclidean_distance < top1_distance:\n",
    "                        top3_distance = top2_distance\n",
    "                        top2_distance = top1_distance\n",
    "                        top1_distance = euclidean_distance\n",
    "                    elif euclidean_distance < top2_distance:\n",
    "                        top3_distance = top2_distance\n",
    "                        top2_distance = euclidean_distance\n",
    "                    elif euclidean_distance < top3_distance:\n",
    "                        top3_distance = euclidean_distance\n",
    "                    \n",
    "                local_model_score = top1_distance + top2_distance + top3_distance\n",
    "                \n",
    "                if local_model_score < top1_smallest_l2_sum:\n",
    "                    top3_smallest_l2_sum = top2_smallest_l2_sum\n",
    "                    top2_smallest_l2_sum = top1_smallest_l2_sum\n",
    "                    top1_smallest_l2_sum = local_model_score\n",
    "                    \n",
    "                    index_top3_smallest_l2_sum = index_top2_smallest_l2_sum\n",
    "                    index_top2_smallest_l2_sum = index_top1_smallest_l2_sum\n",
    "                    index_top1_smallest_l2_sum = current_client_index\n",
    "                elif local_model_score < top2_smallest_l2_sum:\n",
    "                    top3_smallest_l2_sum = top2_smallest_l2_sum\n",
    "                    top2_smallest_l2_sum = local_model_score\n",
    "                    \n",
    "                    index_top3_smallest_l2_sum = index_top2_smallest_l2_sum\n",
    "                    index_top2_smallest_l2_sum = current_client_index\n",
    "                elif local_model_score < top3_smallest_l2_sum:\n",
    "                    top3_smallest_l2_sum = local_model_score\n",
    "                    \n",
    "                    index_top3_smallest_l2_sum = current_client_index\n",
    "                    \n",
    "            result_state_dict[layer_name] += all_models[index_top1_smallest_l2_sum][layer_name].to(device)\n",
    "            result_state_dict[layer_name] += all_models[index_top2_smallest_l2_sum][layer_name].to(device)\n",
    "            result_state_dict[layer_name] += all_models[index_top3_smallest_l2_sum][layer_name].to(device)\n",
    "            \n",
    "            result_state_dict[layer_name] = result_state_dict[layer_name] / k\n",
    "    \n",
    "    return result_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Federated Learning\n",
    "#### 1.9.1 Settings\n",
    "We define some settings related to Federated Learning.\n",
    "These settings can be tweaked during the assignment and make sure that the already implemented FL code in `src` works correctly.\n",
    "The settings are thusly taken from the week 11 tutorial (Federated Learning, dr. Picek)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLSettings:\n",
    "    total_client_count = 6\n",
    "    malignant_client_count = 2\n",
    "    benign_client_count = total_client_count - malignant_client_count\n",
    "    \n",
    "    iid_rate = 0.9\n",
    "    samples_per_client = 384\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1024\n",
    "        \n",
    "    global_aggregation_rounds = 5\n",
    "    local_epochs = 2\n",
    "    client_count_per_round = 5\n",
    "    aggregation_function_name = \"FedAvg\"\n",
    "    \n",
    "    malignant_client_poisoning_rate = 0.5\n",
    "    backdoor_target_class = 0\n",
    "    backdoor_attack = BlendAttack(source_label=None, target_label=backdoor_target_class)\n",
    "    \n",
    "    data_mean = torch.from_numpy(np.array([0.4914, 0.4822, 0.4465]))\n",
    "    data_std = torch.from_numpy(np.array([0.2023, 0.1994, 0.2010]))\n",
    "    \n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(data_mean, data_std),\n",
    "    ])\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(data_mean, data_std),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9.2 Setup\n",
    "We initiate an FL setup using code from `src` and the week 11 tutorial about Federated Learning.\n",
    "We compute the indices of the data samples that we give to each client, so that every client has a local dataset to train on, and we setup both clean and backdoored test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:19, 2523.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 16:37:50.870670: Samples from main class per client: 38\n",
      "2024-05-29 16:37:50.870670: Samples from all classes per client: 346\n",
      "2024-05-29 16:37:50.880637: Main label for clients: {0: 0, 1: 1, 2: 1, 3: 5, 4: 8, 5: 7} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.27it/s]\n"
     ]
    }
   ],
   "source": [
    "cifar10_train = torchvision.datasets.CIFAR10(root=\"d:/Datasets\", download=True, train=True, transform=FLSettings.transform_train)\n",
    "cifar10_test = [p for p in torchvision.datasets.CIFAR10(root=\"d:/Datasets\", download=True, train=False, transform=FLSettings.transform_test)]\n",
    "\n",
    "train_data_by_labels, all_labels, all_training_images = src.Utils.sort_samples_by_labels(cifar10_train)\n",
    "\n",
    "client_data_indices, main_labels_dict = src.Utils.create_client_distributions(\n",
    "    total_client_number=FLSettings.total_client_count,\n",
    "    iid_rate=FLSettings.iid_rate,\n",
    "    samples_per_client=FLSettings.samples_per_client,\n",
    "    all_labels=all_labels,\n",
    "    train_data_by_labels=train_data_by_labels,\n",
    "    all_training_images=all_training_images\n",
    ")\n",
    "\n",
    "all_training_data = [MyDataLoader(cifar10_train, indices, FLSettings.batch_size) for indices in tqdm(client_data_indices)]\n",
    "\n",
    "test_data = src.Utils.batchify(cifar10_test, FLSettings.test_batch_size, len(cifar10_test))\n",
    "test_data = [(x.to(device), y.to(device)) for x, y in test_data]\n",
    "\n",
    "all_test_samples = []\n",
    "for image, label in cifar10_test:\n",
    "    if label == FLSettings.backdoor_target_class:\n",
    "        continue\n",
    "    \n",
    "    all_test_samples.append((image, label))\n",
    "    \n",
    "backdoor_test_data_loader = DataLoader(all_test_samples, batch_size=FLSettings.test_batch_size, shuffle=True)\n",
    "backdoor_test_data = src.PoisoningUtils.BackdoorData(\n",
    "        data_loader=backdoor_test_data_loader,\n",
    "        attack=FLSettings.backdoor_attack,\n",
    "        pdr=1.0,\n",
    "        is_test_dataloader=True,\n",
    "        BACKDOOR_TARGET_CLASS=FLSettings.backdoor_target_class,\n",
    "        MEAN=FLSettings.data_mean,\n",
    "        STD_DEV=FLSettings.data_std,\n",
    "        COMPUTATION_DEVICE=device\n",
    "    )\n",
    "backdoor_test_data.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9.3 Training Procedure\n",
    "We define a single function that performs an entire federated learning scenario, `learn_federated`.\n",
    "This is so that we can easily perform an entire federated learning scenario with slightly altered hyperparameters, such as the number of malignant clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_federated() -> tuple[float, float]:\n",
    "    global_model = NeuralModel(\"GlobalModel\")\n",
    "    local_training_data = []\n",
    "    \n",
    "    for client_data in all_training_data:\n",
    "        local_training_data.append(copy(client_data))\n",
    "    \n",
    "    malignant_client_indexes = np.random.choice(a=FLSettings.total_client_count, size=FLSettings.malignant_client_count, replace=False).tolist()\n",
    "    print(\"Indexes of Malignant Clients:\", malignant_client_indexes)\n",
    "\n",
    "    for client_index in malignant_client_indexes:\n",
    "        local_training_data[client_index] = src.PoisoningUtils.BackdoorData(\n",
    "            data_loader=local_training_data[client_index],\n",
    "            attack=FLSettings.backdoor_attack,\n",
    "            pdr=FLSettings.malignant_client_poisoning_rate,\n",
    "            BACKDOOR_TARGET_CLASS=FLSettings.backdoor_target_class,\n",
    "            MEAN=FLSettings.data_mean,\n",
    "            STD_DEV=FLSettings.data_std,\n",
    "            COMPUTATION_DEVICE=device\n",
    "        )\n",
    "    \n",
    "    local_models = []\n",
    "    for client_index in range(FLSettings.total_client_count):\n",
    "        local_models.append(NeuralModel(f\"LocalModel{client_index}\"))\n",
    "\n",
    "    for _ in range(FLSettings.global_aggregation_rounds):\n",
    "        all_trained_weights = []\n",
    "        \n",
    "        excluded_client_index = np.random.randint(low=0, high=FLSettings.total_client_count, size=1)\n",
    "        print(\"Excluded client this round:\", excluded_client_index)\n",
    "        \n",
    "        for client_index in range(FLSettings.total_client_count):        \n",
    "            if client_index == excluded_client_index:\n",
    "                continue\n",
    "                    \n",
    "            src.Utils.print_timed(f'Client {client_index}')\n",
    "            \n",
    "            trained_weights = src.TrainingUtils.client_training(\n",
    "                global_model_state_dict=global_model.neural_network_state_dict,\n",
    "                local_model=local_models[client_index].neural_network,\n",
    "                local_training_data=local_training_data[client_index],\n",
    "                local_epochs=FLSettings.local_epochs,\n",
    "                printing_prefix='\\t',\n",
    "                COMPUTATION_DEVICE=device\n",
    "            )\n",
    "            \n",
    "            all_trained_weights.append(trained_weights)\n",
    "        \n",
    "        hash_values = src.ModelUtils.get_models_hash(all_trained_weights)\n",
    "        \n",
    "        if FLSettings.aggregation_function_name == \"FedAvg\":\n",
    "            aggregated_weights = fed_avg(all_trained_weights, global_model.neural_network_state_dict)\n",
    "        elif FLSettings.aggregation_function_name == \"Krum\":\n",
    "            aggregated_weights = krum(all_trained_weights, global_model.neural_network_state_dict, FLSettings.malignant_client_count)\n",
    "        else:\n",
    "            ValueError(f\"Invalid aggregation function was chosen in FLSettings: {FLSettings.aggregation_function_name}\")\n",
    "        \n",
    "        src.ModelUtils.check_hashs(all_trained_weights, hash_values)\n",
    "        \n",
    "        global_model.neural_network.load_state_dict(aggregated_weights)\n",
    "        global_model.neural_network_state_dict = aggregated_weights\n",
    "        _ = src.ModelUtils.test(test_data, global_model.neural_network)\n",
    "\n",
    "    accuracy, _ = src.ModelUtils.evaluate_model(\n",
    "        model_to_evaluate=global_model.neural_network,\n",
    "        test_data=test_data,\n",
    "        backdoor_test_data=backdoor_test_data\n",
    "    )\n",
    "    \n",
    "    return accuracy / 100, attack_success_rate(\n",
    "        model=global_model,\n",
    "        adversarial_test_data=backdoor_test_data,\n",
    "        target_label=FLSettings.backdoor_target_class,\n",
    "        source_label=None,\n",
    "        verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Backdoor Attack in Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.a \n",
    "Q: Implement a source-agnostic backdoor attack in FL using the\n",
    "Blend attack with the Hello Kitty image. Below you find a list of parameters/settings to use for this attack. Limit your implementation to these values.\n",
    "You will be investigating the performance of the attack with different number of\n",
    "malicious clients in the network, i.e., 1, 2, or 3. In all cases, a total of 6 clients\n",
    "compose the network. For example, in the first setting you have 1 malicious\n",
    "and 5 benign clients. However, we ask you to select only a subset from all the\n",
    "clients each round to perform the local training. This subset selection should be\n",
    "random, but you are free how you implement this selection procedure. In the\n",
    "end of the training, i.e., after 5 rounds of FL, plot the final ASR (y-axis) and\n",
    "the global (poisoned) model’s task accuracy (also y-axis) versus the number of\n",
    "malicious clients (x-axis). Either make two plots, one for ASR and one for accuracy, or combine the results in one. The following parameters/settings should\n",
    "be used:\n",
    "- **Model**: Load the pre-trained ResNet18Light model from the Federated\n",
    "Learning tutorial.\n",
    "- **Poisoning Rate**: Every malicious client should use a poisoning rate of\n",
    "50% of the local dataset.\n",
    "- **Global Aggregation Rounds**: 5.\n",
    "- **Local Training Epochs**: 2.\n",
    "- **Backdoor Target Class**: 0 (airplane).\n",
    "- **Number Selected Clients Per Round**: 5.\n",
    "- **Aggregation Method**: FedAvg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_metrics_df = pd.DataFrame(columns=[\"Malignant Client Count\", \"Score\", \"Metric\"])\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Indexes of Malignant Clients: [1]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Excluded client this round: [1]\n",
      "2024-05-29 16:38:16.341501: Client 0\n",
      "2024-05-29 16:38:17.062846: \tlocal_epoch   0 | lr 0.2 | ms/batch 715.35| loss  3.91\n",
      "2024-05-29 16:38:17.611714: \tlocal_epoch   1 | lr 0.2 | ms/batch 548.87| loss  1.07\n",
      "2024-05-29 16:38:17.626712: Client 2\n",
      "2024-05-29 16:38:18.189695: \tlocal_epoch   0 | lr 0.2 | ms/batch 552.98| loss  3.33\n",
      "2024-05-29 16:38:18.743678: \tlocal_epoch   1 | lr 0.2 | ms/batch 553.98| loss  0.70\n",
      "2024-05-29 16:38:18.758681: Client 3\n",
      "2024-05-29 16:38:19.308662: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.98| loss  3.26\n",
      "2024-05-29 16:38:19.848519: \tlocal_epoch   1 | lr 0.2 | ms/batch 539.86| loss  0.99\n",
      "2024-05-29 16:38:19.863483: Client 4\n",
      "2024-05-29 16:38:20.412464: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.98| loss  3.90\n",
      "2024-05-29 16:38:20.961449: \tlocal_epoch   1 | lr 0.2 | ms/batch 548.98| loss  1.12\n",
      "2024-05-29 16:38:20.981448: Client 5\n",
      "2024-05-29 16:38:21.538430: \tlocal_epoch   0 | lr 0.2 | ms/batch 551.98| loss  3.88\n",
      "2024-05-29 16:38:22.103415: \tlocal_epoch   1 | lr 0.2 | ms/batch 564.99| loss  1.13\n",
      "2024-05-29 16:38:22.170411: Aggregate 5 models\n",
      "2024-05-29 16:38:25.937812: ___Test GlobalModel_ResNet_18: Average loss: 0.6517, Accuracy: 7816/10000 (78.1600%)\n",
      "Excluded client this round: [2]\n",
      "2024-05-29 16:38:25.939814: Client 0\n",
      "2024-05-29 16:38:26.511800: \tlocal_epoch   0 | lr 0.2 | ms/batch 564.99| loss  0.83\n",
      "2024-05-29 16:38:27.058873: \tlocal_epoch   1 | lr 0.2 | ms/batch 547.07| loss  0.16\n",
      "2024-05-29 16:38:27.078871: Client 1\n",
      "2024-05-29 16:38:27.631417: \tlocal_epoch   0 | lr 0.2 | ms/batch 547.53| loss  9.01\n",
      "2024-05-29 16:38:28.177847: \tlocal_epoch   1 | lr 0.2 | ms/batch 546.43| loss  2.97\n",
      "2024-05-29 16:38:28.196833: Client 3\n",
      "2024-05-29 16:38:28.747781: \tlocal_epoch   0 | lr 0.2 | ms/batch 545.95| loss  0.78\n",
      "2024-05-29 16:38:29.293799: \tlocal_epoch   1 | lr 0.2 | ms/batch 546.02| loss  0.20\n",
      "2024-05-29 16:38:29.307776: Client 4\n",
      "2024-05-29 16:38:29.859770: \tlocal_epoch   0 | lr 0.2 | ms/batch 546.97| loss  0.74\n",
      "2024-05-29 16:38:30.404751: \tlocal_epoch   1 | lr 0.2 | ms/batch 544.98| loss  0.15\n",
      "2024-05-29 16:38:30.425761: Client 5\n",
      "2024-05-29 16:38:31.005729: \tlocal_epoch   0 | lr 0.2 | ms/batch 571.98| loss  1.15\n",
      "2024-05-29 16:38:31.556711: \tlocal_epoch   1 | lr 0.2 | ms/batch 550.98| loss  0.20\n",
      "2024-05-29 16:38:31.615738: Aggregate 5 models\n",
      "2024-05-29 16:38:35.292600: ___Test GlobalModel_ResNet_18: Average loss: 0.7401, Accuracy: 7504/10000 (75.0400%)\n",
      "Excluded client this round: [4]\n",
      "2024-05-29 16:38:35.293594: Client 0\n",
      "2024-05-29 16:38:35.843607: \tlocal_epoch   0 | lr 0.2 | ms/batch 546.01| loss  0.50\n",
      "2024-05-29 16:38:36.387290: \tlocal_epoch   1 | lr 0.2 | ms/batch 543.68| loss  0.10\n",
      "2024-05-29 16:38:36.401292: Client 1\n",
      "2024-05-29 16:38:36.952273: \tlocal_epoch   0 | lr 0.2 | ms/batch 546.98| loss  1.51\n",
      "2024-05-29 16:38:37.495413: \tlocal_epoch   1 | lr 0.2 | ms/batch 543.14| loss  0.50\n",
      "2024-05-29 16:38:37.509416: Client 2\n",
      "2024-05-29 16:38:38.065396: \tlocal_epoch   0 | lr 0.2 | ms/batch 550.98| loss  1.38\n",
      "2024-05-29 16:38:38.608036: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.64| loss  0.41\n",
      "2024-05-29 16:38:38.622043: Client 3\n",
      "2024-05-29 16:38:39.172082: \tlocal_epoch   0 | lr 0.2 | ms/batch 545.06| loss  0.58\n",
      "2024-05-29 16:38:39.715064: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.98| loss  0.20\n",
      "2024-05-29 16:38:39.730032: Client 5\n",
      "2024-05-29 16:38:40.279055: \tlocal_epoch   0 | lr 0.2 | ms/batch 545.00| loss  0.63\n",
      "2024-05-29 16:38:40.815759: \tlocal_epoch   1 | lr 0.2 | ms/batch 536.70| loss  0.13\n",
      "2024-05-29 16:38:40.864761: Aggregate 5 models\n",
      "2024-05-29 16:38:47.840558: ___Test GlobalModel_ResNet_18: Average loss: 0.6691, Accuracy: 7824/10000 (78.2400%)\n",
      "Excluded client this round: [3]\n",
      "2024-05-29 16:38:47.842542: Client 0\n",
      "2024-05-29 16:38:48.386580: \tlocal_epoch   0 | lr 0.2 | ms/batch 538.04| loss  0.15\n",
      "2024-05-29 16:38:48.922547: \tlocal_epoch   1 | lr 0.2 | ms/batch 535.97| loss  0.07\n",
      "2024-05-29 16:38:48.938506: Client 1\n",
      "2024-05-29 16:38:49.482525: \tlocal_epoch   0 | lr 0.2 | ms/batch 539.02| loss  0.67\n",
      "2024-05-29 16:38:50.017343: \tlocal_epoch   1 | lr 0.2 | ms/batch 534.82| loss  0.26\n",
      "2024-05-29 16:38:50.035252: Client 2\n",
      "2024-05-29 16:38:50.578571: \tlocal_epoch   0 | lr 0.2 | ms/batch 539.32| loss  0.18\n",
      "2024-05-29 16:38:51.115590: \tlocal_epoch   1 | lr 0.2 | ms/batch 537.02| loss  0.04\n",
      "2024-05-29 16:38:51.131551: Client 4\n",
      "2024-05-29 16:38:51.678577: \tlocal_epoch   0 | lr 0.2 | ms/batch 540.99| loss  0.40\n",
      "2024-05-29 16:38:52.218518: \tlocal_epoch   1 | lr 0.2 | ms/batch 539.94| loss  0.09\n",
      "2024-05-29 16:38:52.247518: Client 5\n",
      "2024-05-29 16:38:52.812499: \tlocal_epoch   0 | lr 0.2 | ms/batch 554.98| loss  0.24\n",
      "2024-05-29 16:38:53.357313: \tlocal_epoch   1 | lr 0.2 | ms/batch 544.81| loss  0.04\n",
      "2024-05-29 16:38:53.436280: Aggregate 5 models\n",
      "2024-05-29 16:39:00.646648: ___Test GlobalModel_ResNet_18: Average loss: 0.6967, Accuracy: 7751/10000 (77.5100%)\n",
      "Excluded client this round: [5]\n",
      "2024-05-29 16:39:00.648682: Client 0\n",
      "2024-05-29 16:39:01.241629: \tlocal_epoch   0 | lr 0.2 | ms/batch 582.98| loss  0.08\n",
      "2024-05-29 16:39:01.784000: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.37| loss  0.03\n",
      "2024-05-29 16:39:01.807031: Client 1\n",
      "2024-05-29 16:39:02.369017: \tlocal_epoch   0 | lr 0.2 | ms/batch 554.02| loss  0.22\n",
      "2024-05-29 16:39:02.915648: \tlocal_epoch   1 | lr 0.2 | ms/batch 546.63| loss  0.03\n",
      "2024-05-29 16:39:02.938648: Client 2\n",
      "2024-05-29 16:39:03.491598: \tlocal_epoch   0 | lr 0.2 | ms/batch 543.98| loss  0.13\n",
      "2024-05-29 16:39:04.036586: \tlocal_epoch   1 | lr 0.2 | ms/batch 544.99| loss  0.04\n",
      "2024-05-29 16:39:04.057616: Client 3\n",
      "2024-05-29 16:39:04.648561: \tlocal_epoch   0 | lr 0.2 | ms/batch 582.97| loss  0.19\n",
      "2024-05-29 16:39:05.197582: \tlocal_epoch   1 | lr 0.2 | ms/batch 548.02| loss  0.04\n",
      "2024-05-29 16:39:05.223544: Client 4\n",
      "2024-05-29 16:39:05.778525: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.95| loss  0.13\n",
      "2024-05-29 16:39:06.324885: \tlocal_epoch   1 | lr 0.2 | ms/batch 545.36| loss  0.04\n",
      "2024-05-29 16:39:06.451882: Aggregate 5 models\n",
      "2024-05-29 16:39:13.629670: ___Test GlobalModel_ResNet_18: Average loss: 0.7048, Accuracy: 7851/10000 (78.5100%)\n",
      "2024-05-29 16:39:26.798596: Performance of GlobalModel_ResNet_18: MA=78.51 BA=6.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:05<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Success Rate: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Daan\\AppData\\Local\\Temp\\ipykernel_21552\\4107697643.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n"
     ]
    }
   ],
   "source": [
    "FLSettings.malignant_client_count = 1\n",
    "accuracy, asr = learn_federated()\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Malignant Client Count\": [FLSettings.malignant_client_count],\n",
    "    \"Score\": [accuracy],\n",
    "    \"Metric\": [\"(Main Task) Accuracy\"]\n",
    "})])\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Malignant Client Count\": [FLSettings.malignant_client_count],\n",
    "    \"Score\": [asr],\n",
    "    \"Metric\": [\"Attack Success Rate (ASR)\"]\n",
    "})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Indexes of Malignant Clients: [5, 3]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Excluded client this round: [0]\n",
      "2024-05-29 16:39:49.511756: Client 1\n",
      "2024-05-29 16:39:50.272769: \tlocal_epoch   0 | lr 0.2 | ms/batch 751.01| loss  3.31\n",
      "2024-05-29 16:39:50.815752: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.02| loss  0.75\n",
      "2024-05-29 16:39:50.834715: Client 2\n",
      "2024-05-29 16:39:51.383696: \tlocal_epoch   0 | lr 0.2 | ms/batch 541.95| loss  3.33\n",
      "2024-05-29 16:39:51.925719: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.02| loss  0.70\n",
      "2024-05-29 16:39:51.944714: Client 3\n",
      "2024-05-29 16:39:52.494071: \tlocal_epoch   0 | lr 0.2 | ms/batch 542.36| loss  9.42\n",
      "2024-05-29 16:39:53.037027: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.96| loss  3.10\n",
      "2024-05-29 16:39:53.060059: Client 4\n",
      "2024-05-29 16:39:53.616007: \tlocal_epoch   0 | lr 0.2 | ms/batch 546.93| loss  3.90\n",
      "2024-05-29 16:39:54.161261: \tlocal_epoch   1 | lr 0.2 | ms/batch 545.25| loss  1.12\n",
      "2024-05-29 16:39:54.181255: Client 5\n",
      "2024-05-29 16:39:54.735232: \tlocal_epoch   0 | lr 0.2 | ms/batch 547.98| loss 10.32\n",
      "2024-05-29 16:39:55.279136: \tlocal_epoch   1 | lr 0.2 | ms/batch 543.90| loss  3.70\n",
      "2024-05-29 16:39:55.343125: Aggregate 5 models\n",
      "2024-05-29 16:39:59.055043: ___Test GlobalModel_ResNet_18: Average loss: 1.5267, Accuracy: 5056/10000 (50.5600%)\n",
      "Excluded client this round: [2]\n",
      "2024-05-29 16:39:59.055545: Client 0\n",
      "2024-05-29 16:39:59.607956: \tlocal_epoch   0 | lr 0.2 | ms/batch 546.40| loss  5.59\n",
      "2024-05-29 16:40:00.153994: \tlocal_epoch   1 | lr 0.2 | ms/batch 546.04| loss  1.55\n",
      "2024-05-29 16:40:00.174945: Client 1\n",
      "2024-05-29 16:40:00.726921: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.94| loss  2.54\n",
      "2024-05-29 16:40:01.270907: \tlocal_epoch   1 | lr 0.2 | ms/batch 543.99| loss  0.80\n",
      "2024-05-29 16:40:01.289906: Client 3\n",
      "2024-05-29 16:40:01.839947: \tlocal_epoch   0 | lr 0.2 | ms/batch 545.04| loss  1.11\n",
      "2024-05-29 16:40:02.384898: \tlocal_epoch   1 | lr 0.2 | ms/batch 543.98| loss  0.23\n",
      "2024-05-29 16:40:02.403945: Client 4\n",
      "2024-05-29 16:40:02.956912: \tlocal_epoch   0 | lr 0.2 | ms/batch 547.95| loss  2.52\n",
      "2024-05-29 16:40:03.501709: \tlocal_epoch   1 | lr 0.2 | ms/batch 544.80| loss  0.89\n",
      "2024-05-29 16:40:03.523677: Client 5\n",
      "2024-05-29 16:40:04.075922: \tlocal_epoch   0 | lr 0.2 | ms/batch 547.22| loss  1.10\n",
      "2024-05-29 16:40:04.620929: \tlocal_epoch   1 | lr 0.2 | ms/batch 545.01| loss  0.20\n",
      "2024-05-29 16:40:04.681931: Aggregate 5 models\n",
      "2024-05-29 16:40:08.397818: ___Test GlobalModel_ResNet_18: Average loss: 0.6787, Accuracy: 7799/10000 (77.9900%)\n",
      "Excluded client this round: [2]\n",
      "2024-05-29 16:40:08.399269: Client 0\n",
      "2024-05-29 16:40:08.948968: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.69| loss  0.98\n",
      "2024-05-29 16:40:09.490909: \tlocal_epoch   1 | lr 0.2 | ms/batch 541.94| loss  0.19\n",
      "2024-05-29 16:40:09.509874: Client 1\n",
      "2024-05-29 16:40:10.060996: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.09| loss  0.36\n",
      "2024-05-29 16:40:10.606039: \tlocal_epoch   1 | lr 0.2 | ms/batch 545.04| loss  0.08\n",
      "2024-05-29 16:40:10.622981: Client 3\n",
      "2024-05-29 16:40:11.175996: \tlocal_epoch   0 | lr 0.2 | ms/batch 546.98| loss  1.43\n",
      "2024-05-29 16:40:11.718981: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.99| loss  0.46\n",
      "2024-05-29 16:40:11.736987: Client 4\n",
      "2024-05-29 16:40:12.286459: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.48| loss  0.41\n",
      "2024-05-29 16:40:12.830414: \tlocal_epoch   1 | lr 0.2 | ms/batch 543.96| loss  0.10\n",
      "2024-05-29 16:40:12.848408: Client 5\n",
      "2024-05-29 16:40:13.398915: \tlocal_epoch   0 | lr 0.2 | ms/batch 545.51| loss  1.52\n",
      "2024-05-29 16:40:13.945849: \tlocal_epoch   1 | lr 0.2 | ms/batch 546.93| loss  0.29\n",
      "2024-05-29 16:40:14.018850: Aggregate 5 models\n",
      "2024-05-29 16:40:21.308829: ___Test GlobalModel_ResNet_18: Average loss: 0.8226, Accuracy: 7243/10000 (72.4300%)\n",
      "Excluded client this round: [0]\n",
      "2024-05-29 16:40:21.309831: Client 1\n",
      "2024-05-29 16:40:21.859106: \tlocal_epoch   0 | lr 0.2 | ms/batch 541.30| loss  0.39\n",
      "2024-05-29 16:40:22.400085: \tlocal_epoch   1 | lr 0.2 | ms/batch 539.96| loss  0.13\n",
      "2024-05-29 16:40:22.417084: Client 2\n",
      "2024-05-29 16:40:22.962258: \tlocal_epoch   0 | lr 0.2 | ms/batch 539.17| loss  2.14\n",
      "2024-05-29 16:40:23.501260: \tlocal_epoch   1 | lr 0.2 | ms/batch 539.00| loss  0.90\n",
      "2024-05-29 16:40:23.518241: Client 3\n",
      "2024-05-29 16:40:24.066232: \tlocal_epoch   0 | lr 0.2 | ms/batch 542.97| loss  0.16\n",
      "2024-05-29 16:40:24.606229: \tlocal_epoch   1 | lr 0.2 | ms/batch 539.00| loss  0.03\n",
      "2024-05-29 16:40:24.624206: Client 4\n",
      "2024-05-29 16:40:25.173208: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.00| loss  0.46\n",
      "2024-05-29 16:40:25.711213: \tlocal_epoch   1 | lr 0.2 | ms/batch 538.00| loss  0.17\n",
      "2024-05-29 16:40:25.733191: Client 5\n",
      "2024-05-29 16:40:26.282166: \tlocal_epoch   0 | lr 0.2 | ms/batch 543.95| loss  0.16\n",
      "2024-05-29 16:40:26.825148: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.98| loss  0.03\n",
      "2024-05-29 16:40:27.056142: Aggregate 5 models\n",
      "2024-05-29 16:40:34.236023: ___Test GlobalModel_ResNet_18: Average loss: 0.6747, Accuracy: 7838/10000 (78.3800%)\n",
      "Excluded client this round: [0]\n",
      "2024-05-29 16:40:34.236992: Client 1\n",
      "2024-05-29 16:40:34.783262: \tlocal_epoch   0 | lr 0.2 | ms/batch 540.28| loss  0.07\n",
      "2024-05-29 16:40:35.320237: \tlocal_epoch   1 | lr 0.2 | ms/batch 536.98| loss  0.03\n",
      "2024-05-29 16:40:35.337274: Client 2\n",
      "2024-05-29 16:40:35.883222: \tlocal_epoch   0 | lr 0.2 | ms/batch 539.99| loss  0.16\n",
      "2024-05-29 16:40:36.422206: \tlocal_epoch   1 | lr 0.2 | ms/batch 538.98| loss  0.04\n",
      "2024-05-29 16:40:36.443241: Client 3\n",
      "2024-05-29 16:40:36.990184: \tlocal_epoch   0 | lr 0.2 | ms/batch 538.94| loss  0.43\n",
      "2024-05-29 16:40:37.535172: \tlocal_epoch   1 | lr 0.2 | ms/batch 544.99| loss  0.06\n",
      "2024-05-29 16:40:37.560174: Client 4\n",
      "2024-05-29 16:40:38.107152: \tlocal_epoch   0 | lr 0.2 | ms/batch 540.95| loss  0.09\n",
      "2024-05-29 16:40:38.645133: \tlocal_epoch   1 | lr 0.2 | ms/batch 537.98| loss  0.03\n",
      "2024-05-29 16:40:38.673152: Client 5\n",
      "2024-05-29 16:40:39.230159: \tlocal_epoch   0 | lr 0.2 | ms/batch 548.99| loss  0.45\n",
      "2024-05-29 16:40:39.772727: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.57| loss  0.03\n",
      "2024-05-29 16:40:39.856711: Aggregate 5 models\n",
      "2024-05-29 16:40:47.101488: ___Test GlobalModel_ResNet_18: Average loss: 0.7511, Accuracy: 7642/10000 (76.4200%)\n",
      "2024-05-29 16:41:00.345834: Performance of GlobalModel_ResNet_18: MA=76.42 BA=0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:05<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Success Rate: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "FLSettings.malignant_client_count = 2\n",
    "accuracy, asr = learn_federated()\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Malignant Client Count\": [FLSettings.malignant_client_count],\n",
    "    \"Score\": [accuracy],\n",
    "    \"Metric\": [\"(Main Task) Accuracy\"]\n",
    "})])\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Malignant Client Count\": [FLSettings.malignant_client_count],\n",
    "    \"Score\": [asr],\n",
    "    \"Metric\": [\"Attack Success Rate (ASR)\"]\n",
    "})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Indexes of Malignant Clients: [5, 1, 0]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Excluded client this round: [0]\n",
      "2024-05-29 16:41:21.805775: Client 1\n",
      "2024-05-29 16:41:22.641746: \tlocal_epoch   0 | lr 0.2 | ms/batch 826.97| loss  9.38\n",
      "2024-05-29 16:41:23.182937: \tlocal_epoch   1 | lr 0.2 | ms/batch 541.19| loss  3.04\n",
      "2024-05-29 16:41:23.203453: Client 2\n",
      "2024-05-29 16:41:23.754462: \tlocal_epoch   0 | lr 0.2 | ms/batch 546.01| loss  3.33\n",
      "2024-05-29 16:41:24.297411: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.95| loss  0.70\n",
      "2024-05-29 16:41:24.317413: Client 3\n",
      "2024-05-29 16:41:24.873395: \tlocal_epoch   0 | lr 0.2 | ms/batch 547.95| loss  3.26\n",
      "2024-05-29 16:41:25.416414: \tlocal_epoch   1 | lr 0.2 | ms/batch 543.02| loss  0.99\n",
      "2024-05-29 16:41:25.439377: Client 4\n",
      "2024-05-29 16:41:25.990893: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.52| loss  3.90\n",
      "2024-05-29 16:41:26.533669: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.78| loss  1.12\n",
      "2024-05-29 16:41:26.557664: Client 5\n",
      "2024-05-29 16:41:27.114647: \tlocal_epoch   0 | lr 0.2 | ms/batch 549.95| loss 10.32\n",
      "2024-05-29 16:41:27.681668: \tlocal_epoch   1 | lr 0.2 | ms/batch 566.01| loss  3.70\n",
      "2024-05-29 16:41:27.756630: Aggregate 5 models\n",
      "2024-05-29 16:41:31.438548: ___Test GlobalModel_ResNet_18: Average loss: 1.3772, Accuracy: 5422/10000 (54.2200%)\n",
      "Excluded client this round: [4]\n",
      "2024-05-29 16:41:31.440513: Client 0\n",
      "2024-05-29 16:41:31.985501: \tlocal_epoch   0 | lr 0.2 | ms/batch 539.99| loss  2.89\n",
      "2024-05-29 16:41:32.526620: \tlocal_epoch   1 | lr 0.2 | ms/batch 541.12| loss  0.57\n",
      "2024-05-29 16:41:32.544587: Client 1\n",
      "2024-05-29 16:41:33.105572: \tlocal_epoch   0 | lr 0.2 | ms/batch 551.98| loss  1.07\n",
      "2024-05-29 16:41:33.646554: \tlocal_epoch   1 | lr 0.2 | ms/batch 540.98| loss  0.17\n",
      "2024-05-29 16:41:33.666574: Client 2\n",
      "2024-05-29 16:41:34.212656: \tlocal_epoch   0 | lr 0.2 | ms/batch 540.10| loss  2.56\n",
      "2024-05-29 16:41:34.750640: \tlocal_epoch   1 | lr 0.2 | ms/batch 537.98| loss  0.77\n",
      "2024-05-29 16:41:34.771640: Client 3\n",
      "2024-05-29 16:41:35.318327: \tlocal_epoch   0 | lr 0.2 | ms/batch 540.71| loss  2.01\n",
      "2024-05-29 16:41:35.859071: \tlocal_epoch   1 | lr 0.2 | ms/batch 540.74| loss  0.53\n",
      "2024-05-29 16:41:35.879051: Client 5\n",
      "2024-05-29 16:41:36.425997: \tlocal_epoch   0 | lr 0.2 | ms/batch 541.95| loss  1.20\n",
      "2024-05-29 16:41:36.964980: \tlocal_epoch   1 | lr 0.2 | ms/batch 537.98| loss  0.20\n",
      "2024-05-29 16:41:37.027988: Aggregate 5 models\n",
      "2024-05-29 16:41:40.708870: ___Test GlobalModel_ResNet_18: Average loss: 0.8157, Accuracy: 7206/10000 (72.0600%)\n",
      "Excluded client this round: [2]\n",
      "2024-05-29 16:41:40.710865: Client 0\n",
      "2024-05-29 16:41:41.257847: \tlocal_epoch   0 | lr 0.2 | ms/batch 541.98| loss  0.72\n",
      "2024-05-29 16:41:41.799256: \tlocal_epoch   1 | lr 0.2 | ms/batch 540.41| loss  0.17\n",
      "2024-05-29 16:41:41.817253: Client 1\n",
      "2024-05-29 16:41:42.369323: \tlocal_epoch   0 | lr 0.2 | ms/batch 544.07| loss  0.43\n",
      "2024-05-29 16:41:42.914308: \tlocal_epoch   1 | lr 0.2 | ms/batch 544.98| loss  0.06\n",
      "2024-05-29 16:41:42.946304: Client 3\n",
      "2024-05-29 16:41:43.501319: \tlocal_epoch   0 | lr 0.2 | ms/batch 545.01| loss  0.53\n",
      "2024-05-29 16:41:44.042269: \tlocal_epoch   1 | lr 0.2 | ms/batch 540.95| loss  0.14\n",
      "2024-05-29 16:41:44.060269: Client 4\n",
      "2024-05-29 16:41:44.611284: \tlocal_epoch   0 | lr 0.2 | ms/batch 545.02| loss  1.59\n",
      "2024-05-29 16:41:45.218910: \tlocal_epoch   1 | lr 0.2 | ms/batch 607.63| loss  0.65\n",
      "2024-05-29 16:41:45.235907: Client 5\n",
      "2024-05-29 16:41:45.780471: \tlocal_epoch   0 | lr 0.2 | ms/batch 538.53| loss  0.70\n",
      "2024-05-29 16:41:46.318795: \tlocal_epoch   1 | lr 0.2 | ms/batch 537.37| loss  0.07\n",
      "2024-05-29 16:41:46.383773: Aggregate 5 models\n",
      "2024-05-29 16:41:53.577550: ___Test GlobalModel_ResNet_18: Average loss: 0.7514, Accuracy: 7494/10000 (74.9400%)\n",
      "Excluded client this round: [3]\n",
      "2024-05-29 16:41:53.579513: Client 0\n",
      "2024-05-29 16:41:54.129428: \tlocal_epoch   0 | lr 0.2 | ms/batch 541.91| loss  0.22\n",
      "2024-05-29 16:41:54.668403: \tlocal_epoch   1 | lr 0.2 | ms/batch 538.98| loss  0.04\n",
      "2024-05-29 16:41:54.684378: Client 1\n",
      "2024-05-29 16:41:55.233170: \tlocal_epoch   0 | lr 0.2 | ms/batch 541.79| loss  0.10\n",
      "2024-05-29 16:41:55.774191: \tlocal_epoch   1 | lr 0.2 | ms/batch 541.02| loss  0.03\n",
      "2024-05-29 16:41:55.794154: Client 2\n",
      "2024-05-29 16:41:56.347171: \tlocal_epoch   0 | lr 0.2 | ms/batch 548.02| loss  0.69\n",
      "2024-05-29 16:41:56.886088: \tlocal_epoch   1 | lr 0.2 | ms/batch 538.92| loss  0.32\n",
      "2024-05-29 16:41:56.903068: Client 4\n",
      "2024-05-29 16:41:57.447036: \tlocal_epoch   0 | lr 0.2 | ms/batch 538.98| loss  0.56\n",
      "2024-05-29 16:41:57.985054: \tlocal_epoch   1 | lr 0.2 | ms/batch 537.02| loss  0.22\n",
      "2024-05-29 16:41:58.004025: Client 5\n",
      "2024-05-29 16:41:58.550011: \tlocal_epoch   0 | lr 0.2 | ms/batch 539.99| loss  0.16\n",
      "2024-05-29 16:41:59.091991: \tlocal_epoch   1 | lr 0.2 | ms/batch 541.98| loss  0.03\n",
      "2024-05-29 16:41:59.166018: Aggregate 5 models\n",
      "2024-05-29 16:42:06.296534: ___Test GlobalModel_ResNet_18: Average loss: 0.7296, Accuracy: 7681/10000 (76.8100%)\n",
      "Excluded client this round: [4]\n",
      "2024-05-29 16:42:06.298567: Client 0\n",
      "2024-05-29 16:42:06.843603: \tlocal_epoch   0 | lr 0.2 | ms/batch 539.07| loss  0.17\n",
      "2024-05-29 16:42:07.384584: \tlocal_epoch   1 | lr 0.2 | ms/batch 540.98| loss  0.02\n",
      "2024-05-29 16:42:07.408585: Client 1\n",
      "2024-05-29 16:42:07.957570: \tlocal_epoch   0 | lr 0.2 | ms/batch 541.98| loss  0.14\n",
      "2024-05-29 16:42:08.504553: \tlocal_epoch   1 | lr 0.2 | ms/batch 546.98| loss  0.02\n",
      "2024-05-29 16:42:08.526550: Client 2\n",
      "2024-05-29 16:42:09.074571: \tlocal_epoch   0 | lr 0.2 | ms/batch 542.02| loss  0.11\n",
      "2024-05-29 16:42:09.611557: \tlocal_epoch   1 | lr 0.2 | ms/batch 536.99| loss  0.04\n",
      "2024-05-29 16:42:09.630188: Client 3\n",
      "2024-05-29 16:42:10.178762: \tlocal_epoch   0 | lr 0.2 | ms/batch 543.57| loss  0.23\n",
      "2024-05-29 16:42:10.721747: \tlocal_epoch   1 | lr 0.2 | ms/batch 542.99| loss  0.06\n",
      "2024-05-29 16:42:10.740748: Client 5\n",
      "2024-05-29 16:42:11.323739: \tlocal_epoch   0 | lr 0.2 | ms/batch 576.99| loss  0.18\n",
      "2024-05-29 16:42:11.867753: \tlocal_epoch   1 | lr 0.2 | ms/batch 544.01| loss  0.02\n",
      "2024-05-29 16:42:11.931719: Aggregate 5 models\n",
      "2024-05-29 16:42:19.101492: ___Test GlobalModel_ResNet_18: Average loss: 0.7854, Accuracy: 7591/10000 (75.9100%)\n",
      "2024-05-29 16:42:32.352082: Performance of GlobalModel_ResNet_18: MA=75.91 BA=0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Success Rate: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "FLSettings.malignant_client_count = 3\n",
    "accuracy, asr = learn_federated()\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Malignant Client Count\": [FLSettings.malignant_client_count],\n",
    "    \"Score\": [accuracy],\n",
    "    \"Metric\": [\"(Main Task) Accuracy\"]\n",
    "})])\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Malignant Client Count\": [FLSettings.malignant_client_count],\n",
    "    \"Score\": [asr],\n",
    "    \"Metric\": [\"Attack Success Rate (ASR)\"]\n",
    "})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Malignant Client Count</th>\n",
       "      <th>Score</th>\n",
       "      <th>Metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.785100</td>\n",
       "      <td>(Main Task) Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>Attack Success Rate (ASR)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.764200</td>\n",
       "      <td>(Main Task) Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.992111</td>\n",
       "      <td>Attack Success Rate (ASR)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.759100</td>\n",
       "      <td>(Main Task) Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>Attack Success Rate (ASR)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Malignant Client Count     Score                     Metric\n",
       "0                      1  0.785100       (Main Task) Accuracy\n",
       "0                      1  0.923000  Attack Success Rate (ASR)\n",
       "0                      2  0.764200       (Main Task) Accuracy\n",
       "0                      2  0.992111  Attack Success Rate (ASR)\n",
       "0                      3  0.759100       (Main Task) Accuracy\n",
       "0                      3  0.991333  Attack Success Rate (ASR)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(data=fl_metrics_df, x=\"Malignant Client Count\", y=\"Score\", hue=\"Metric\")\n",
    "\n",
    "display(fl_metrics_df)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.b \n",
    "Q: In question 2.1.a we asked you to use a subset of clients each round.\n",
    "What do you think is the influence of the number of selected clients on the\n",
    "performance of the backdoor attack in the federated setting? Share your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: I think that the influence of the number of selected clients on the performance of the backdoor attack will vary significantly depending on what we assume that the share of malignant clients will be.\n",
    "If the share of malignant clients is small, then I expect the procedure to be a mildly useful defense, as the global model has an opportunity to recuperate from learning the backdoor every once in a while when a malignant user is excluded.\n",
    "However, if the share of malignant clients is bigger, or even approaching a 50/50 split between benign and malignant clients, then I think that the procedure may only make the backdoor worse, since there is a real chance that there will be round where the global model aggregates from mostly or exclusively malignant clients.\n",
    "This dynamic holds true for when the number of selected clients changes: the smaller the number of selected clients is, the more likely it is that the model aggregates from mostly malignant clients for some rounds, and the more likely it is that the backdoor will be inserted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.c\n",
    "Q: In question 2.1.a we asked you to perform Federated Learning using\n",
    "the FedAvg method for aggregation. Now using the same settings, but with just\n",
    "1 malicious client, perform federated learning by making use of the **Krum** aggregation method. Plot the final ASR (y-axis) and global (poisoned) model task\n",
    "accuracy (y-axis) for both the FedAvg and Krum methods (x-axis). Compare\n",
    "the methods and share your conclusions on how both methods affect the ASR\n",
    "and accuracy. For this homework question we ask you to assume 1 malicious\n",
    "client, so f = 1. Also, only consider the subset of local models each round for\n",
    "aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_metrics_df = pd.DataFrame(columns=[\"Aggregation Method\", \"Score\", \"Metric\"])\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Indexes of Malignant Clients: [3]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Excluded client this round: [1]\n",
      "2024-05-29 18:08:02.412211: Client 0\n",
      "2024-05-29 18:08:03.590202: \tlocal_epoch   0 | lr 0.2 | ms/batch 1172.99| loss  3.91\n",
      "2024-05-29 18:08:04.548227: \tlocal_epoch   1 | lr 0.2 | ms/batch 958.02| loss  1.07\n",
      "2024-05-29 18:08:04.565377: Client 2\n",
      "2024-05-29 18:08:05.639371: \tlocal_epoch   0 | lr 0.2 | ms/batch 1068.99| loss  3.33\n",
      "2024-05-29 18:08:06.694367: \tlocal_epoch   1 | lr 0.2 | ms/batch 1055.00| loss  0.70\n",
      "2024-05-29 18:08:06.712365: Client 3\n",
      "2024-05-29 18:08:07.699913: \tlocal_epoch   0 | lr 0.2 | ms/batch 983.55| loss  9.42\n",
      "2024-05-29 18:08:08.747871: \tlocal_epoch   1 | lr 0.2 | ms/batch 1047.96| loss  3.10\n",
      "2024-05-29 18:08:08.769874: Client 4\n",
      "2024-05-29 18:08:09.806703: \tlocal_epoch   0 | lr 0.2 | ms/batch 1032.83| loss  3.90\n",
      "2024-05-29 18:08:10.876699: \tlocal_epoch   1 | lr 0.2 | ms/batch 1070.00| loss  1.12\n",
      "2024-05-29 18:08:10.892698: Client 5\n",
      "2024-05-29 18:08:11.906689: \tlocal_epoch   0 | lr 0.2 | ms/batch 1005.96| loss  3.88\n",
      "2024-05-29 18:08:12.912695: \tlocal_epoch   1 | lr 0.2 | ms/batch 1006.01| loss  1.13\n",
      "2024-05-29 18:08:12.973684: Aggregate 5 models\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "2024-05-29 18:08:33.180648: ___Test GlobalModel_ResNet_18: Average loss: 0.8631, Accuracy: 7098/10000 (70.9800%)\n",
      "Excluded client this round: [4]\n",
      "2024-05-29 18:08:33.182638: Client 0\n",
      "2024-05-29 18:08:33.947671: \tlocal_epoch   0 | lr 0.2 | ms/batch 760.03| loss  1.20\n",
      "2024-05-29 18:08:34.693640: \tlocal_epoch   1 | lr 0.2 | ms/batch 745.97| loss  0.33\n",
      "2024-05-29 18:08:34.709630: Client 1\n",
      "2024-05-29 18:08:35.497665: \tlocal_epoch   0 | lr 0.2 | ms/batch 782.03| loss  3.98\n",
      "2024-05-29 18:08:36.296624: \tlocal_epoch   1 | lr 0.2 | ms/batch 798.96| loss  1.13\n",
      "2024-05-29 18:08:36.342623: Client 2\n",
      "2024-05-29 18:08:37.175653: \tlocal_epoch   0 | lr 0.2 | ms/batch 822.03| loss  1.30\n",
      "2024-05-29 18:08:37.985646: \tlocal_epoch   1 | lr 0.2 | ms/batch 809.99| loss  0.37\n",
      "2024-05-29 18:08:38.004613: Client 3\n",
      "2024-05-29 18:08:38.811605: \tlocal_epoch   0 | lr 0.2 | ms/batch 802.99| loss  1.47\n",
      "2024-05-29 18:08:39.591632: \tlocal_epoch   1 | lr 0.2 | ms/batch 780.03| loss  0.47\n",
      "2024-05-29 18:08:39.608623: Client 5\n",
      "2024-05-29 18:08:40.449598: \tlocal_epoch   0 | lr 0.2 | ms/batch 834.00| loss  1.54\n",
      "2024-05-29 18:08:41.265595: \tlocal_epoch   1 | lr 0.2 | ms/batch 816.00| loss  0.35\n",
      "2024-05-29 18:08:41.332592: Aggregate 5 models\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "2024-05-29 18:09:02.249520: ___Test GlobalModel_ResNet_18: Average loss: 0.6258, Accuracy: 7902/10000 (79.0200%)\n",
      "Excluded client this round: [5]\n",
      "2024-05-29 18:09:02.250527: Client 0\n",
      "2024-05-29 18:09:03.049296: \tlocal_epoch   0 | lr 0.2 | ms/batch 791.82| loss  0.31\n",
      "2024-05-29 18:09:03.795884: \tlocal_epoch   1 | lr 0.2 | ms/batch 746.59| loss  0.07\n",
      "2024-05-29 18:09:03.812846: Client 1\n",
      "2024-05-29 18:09:04.594877: \tlocal_epoch   0 | lr 0.2 | ms/batch 777.03| loss  0.63\n",
      "2024-05-29 18:09:05.352874: \tlocal_epoch   1 | lr 0.2 | ms/batch 757.03| loss  0.10\n",
      "2024-05-29 18:09:05.367867: Client 2\n",
      "2024-05-29 18:09:06.161834: \tlocal_epoch   0 | lr 0.2 | ms/batch 790.00| loss  0.26\n",
      "2024-05-29 18:09:06.970839: \tlocal_epoch   1 | lr 0.2 | ms/batch 808.00| loss  0.06\n",
      "2024-05-29 18:09:06.994832: Client 3\n",
      "2024-05-29 18:09:07.897823: \tlocal_epoch   0 | lr 0.2 | ms/batch 896.99| loss  1.00\n",
      "2024-05-29 18:09:08.797819: \tlocal_epoch   1 | lr 0.2 | ms/batch 898.99| loss  0.42\n",
      "2024-05-29 18:09:08.819817: Client 4\n",
      "2024-05-29 18:09:09.686845: \tlocal_epoch   0 | lr 0.2 | ms/batch 860.02| loss  0.97\n",
      "2024-05-29 18:09:10.537850: \tlocal_epoch   1 | lr 0.2 | ms/batch 851.00| loss  0.24\n",
      "2024-05-29 18:09:10.613842: Aggregate 5 models\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "2024-05-29 18:09:31.339430: ___Test GlobalModel_ResNet_18: Average loss: 0.7001, Accuracy: 7724/10000 (77.2400%)\n",
      "Excluded client this round: [1]\n",
      "2024-05-29 18:09:31.340430: Client 0\n",
      "2024-05-29 18:09:32.206423: \tlocal_epoch   0 | lr 0.2 | ms/batch 859.97| loss  0.11\n",
      "2024-05-29 18:09:33.072134: \tlocal_epoch   1 | lr 0.2 | ms/batch 865.71| loss  0.04\n",
      "2024-05-29 18:09:33.095134: Client 2\n",
      "2024-05-29 18:09:33.913126: \tlocal_epoch   0 | lr 0.2 | ms/batch 807.96| loss  0.16\n",
      "2024-05-29 18:09:34.736129: \tlocal_epoch   1 | lr 0.2 | ms/batch 823.00| loss  0.04\n",
      "2024-05-29 18:09:34.760123: Client 3\n",
      "2024-05-29 18:09:35.459117: \tlocal_epoch   0 | lr 0.2 | ms/batch 691.98| loss  0.36\n",
      "2024-05-29 18:09:36.174113: \tlocal_epoch   1 | lr 0.2 | ms/batch 715.00| loss  0.11\n",
      "2024-05-29 18:09:36.198159: Client 4\n",
      "2024-05-29 18:09:36.999032: \tlocal_epoch   0 | lr 0.2 | ms/batch 793.87| loss  0.23\n",
      "2024-05-29 18:09:37.789017: \tlocal_epoch   1 | lr 0.2 | ms/batch 789.99| loss  0.05\n",
      "2024-05-29 18:09:37.811055: Client 5\n",
      "2024-05-29 18:09:38.707007: \tlocal_epoch   0 | lr 0.2 | ms/batch 889.99| loss  0.45\n",
      "2024-05-29 18:09:39.598139: \tlocal_epoch   1 | lr 0.2 | ms/batch 891.13| loss  0.07\n",
      "2024-05-29 18:09:39.678097: Aggregate 5 models\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "2024-05-29 18:10:01.021547: ___Test GlobalModel_ResNet_18: Average loss: 0.6548, Accuracy: 7925/10000 (79.2500%)\n",
      "Excluded client this round: [1]\n",
      "2024-05-29 18:10:01.022543: Client 0\n",
      "2024-05-29 18:10:02.016533: \tlocal_epoch   0 | lr 0.2 | ms/batch 979.99| loss  0.07\n",
      "2024-05-29 18:10:02.984528: \tlocal_epoch   1 | lr 0.2 | ms/batch 968.00| loss  0.03\n",
      "2024-05-29 18:10:03.008530: Client 2\n",
      "2024-05-29 18:10:04.001519: \tlocal_epoch   0 | lr 0.2 | ms/batch 981.99| loss  0.08\n",
      "2024-05-29 18:10:04.988518: \tlocal_epoch   1 | lr 0.2 | ms/batch 987.00| loss  0.03\n",
      "2024-05-29 18:10:05.007521: Client 3\n",
      "2024-05-29 18:10:05.945514: \tlocal_epoch   0 | lr 0.2 | ms/batch 930.00| loss  0.18\n",
      "2024-05-29 18:10:06.857508: \tlocal_epoch   1 | lr 0.2 | ms/batch 910.99| loss  0.02\n",
      "2024-05-29 18:10:06.884503: Client 4\n",
      "2024-05-29 18:10:07.720503: \tlocal_epoch   0 | lr 0.2 | ms/batch 831.00| loss  0.11\n",
      "2024-05-29 18:10:08.521037: \tlocal_epoch   1 | lr 0.2 | ms/batch 799.53| loss  0.03\n",
      "2024-05-29 18:10:08.544038: Client 5\n",
      "2024-05-29 18:10:09.487035: \tlocal_epoch   0 | lr 0.2 | ms/batch 937.00| loss  0.12\n",
      "2024-05-29 18:10:10.434027: \tlocal_epoch   1 | lr 0.2 | ms/batch 945.99| loss  0.03\n",
      "2024-05-29 18:10:10.504029: Aggregate 5 models\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "Fuck! bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn1.num_batches_tracked\n",
      "Fuck! layer1.0.bn2.num_batches_tracked\n",
      "Fuck! layer1.1.bn1.num_batches_tracked\n",
      "Fuck! layer1.1.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.bn1.num_batches_tracked\n",
      "Fuck! layer2.0.bn2.num_batches_tracked\n",
      "Fuck! layer2.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer2.1.bn1.num_batches_tracked\n",
      "Fuck! layer2.1.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.bn1.num_batches_tracked\n",
      "Fuck! layer3.0.bn2.num_batches_tracked\n",
      "Fuck! layer3.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer3.1.bn1.num_batches_tracked\n",
      "Fuck! layer3.1.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.bn1.num_batches_tracked\n",
      "Fuck! layer4.0.bn2.num_batches_tracked\n",
      "Fuck! layer4.0.shortcut.1.num_batches_tracked\n",
      "Fuck! layer4.1.bn1.num_batches_tracked\n",
      "Fuck! layer4.1.bn2.num_batches_tracked\n",
      "2024-05-29 18:10:31.524669: ___Test GlobalModel_ResNet_18: Average loss: 0.6848, Accuracy: 7918/10000 (79.1800%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m FLSettings\u001b[38;5;241m.\u001b[39mmalignant_client_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m FLSettings\u001b[38;5;241m.\u001b[39maggregation_function_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFedAvg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m accuracy, asr \u001b[38;5;241m=\u001b[39m \u001b[43mlearn_federated\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m fl_metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([fl_metrics_df, pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict({\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation Method\u001b[39m\u001b[38;5;124m\"\u001b[39m: [FLSettings\u001b[38;5;241m.\u001b[39maggregation_function_name],\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m: [accuracy],\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Main Task) Accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m })])\n\u001b[0;32m     12\u001b[0m fl_metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([fl_metrics_df, pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict({\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation Method\u001b[39m\u001b[38;5;124m\"\u001b[39m: [FLSettings\u001b[38;5;241m.\u001b[39maggregation_function_name],\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m: [asr],\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttack Success Rate (ASR)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     16\u001b[0m })])\n",
      "Cell \u001b[1;32mIn[53], line 64\u001b[0m, in \u001b[0;36mlearn_federated\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m     global_model\u001b[38;5;241m.\u001b[39mneural_network_state_dict \u001b[38;5;241m=\u001b[39m aggregated_weights\n\u001b[0;32m     62\u001b[0m     _ \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mModelUtils\u001b[38;5;241m.\u001b[39mtest(test_data, global_model\u001b[38;5;241m.\u001b[39mneural_network)\n\u001b[1;32m---> 64\u001b[0m accuracy, _ \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_to_evaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneural_network\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackdoor_test_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackdoor_test_data\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m, attack_success_rate(\n\u001b[0;32m     71\u001b[0m     model\u001b[38;5;241m=\u001b[39mglobal_model,\n\u001b[0;32m     72\u001b[0m     adversarial_test_data\u001b[38;5;241m=\u001b[39mbackdoor_test_data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     76\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Daan\\Documents\\Projecten\\ru-security-and-privacy-of-machine-learning-23-24\\assignments\\assignment-3\\src\\ModelUtils.py:97\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model_to_evaluate, test_data, backdoor_test_data, name, verbose)\u001b[0m\n\u001b[0;32m     95\u001b[0m     name \u001b[38;5;241m=\u001b[39m model_to_evaluate\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m     96\u001b[0m main_task_accuracy \u001b[38;5;241m=\u001b[39m test(test_data, model_to_evaluate, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 97\u001b[0m backdoor_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackdoor_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_to_evaluate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    100\u001b[0m     print_timed(\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerformance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: MA=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmain_task_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m1.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m BA=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackdoor_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m1.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Daan\\Documents\\Projecten\\ru-security-and-privacy-of-machine-learning-23-24\\assignments\\assignment-3\\src\\ModelUtils.py:22\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(data_source, model, verbose)\u001b[0m\n\u001b[0;32m     19\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#targets = targets.type(torch.LongTensor).cuda()\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# sum up batch loss\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# get the index of the max log-probability\u001b[39;00m\n\u001b[0;32m     24\u001b[0m pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FLSettings.malignant_client_count = 1\n",
    "FLSettings.aggregation_function_name = \"FedAvg\"\n",
    "\n",
    "accuracy, asr = learn_federated()\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Aggregation Method\": [FLSettings.aggregation_function_name],\n",
    "    \"Score\": [accuracy],\n",
    "    \"Metric\": [\"(Main Task) Accuracy\"]\n",
    "})])\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Aggregation Method\": [FLSettings.aggregation_function_name],\n",
    "    \"Score\": [asr],\n",
    "    \"Metric\": [\"Attack Success Rate (ASR)\"]\n",
    "})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Indexes of Malignant Clients: [3]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Excluded client this round: [5]\n",
      "2024-05-29 17:49:09.538896: Client 0\n",
      "2024-05-29 17:49:10.196886: \tlocal_epoch   0 | lr 0.2 | ms/batch 650.99| loss  3.91\n",
      "2024-05-29 17:49:10.767919: \tlocal_epoch   1 | lr 0.2 | ms/batch 571.03| loss  1.07\n",
      "2024-05-29 17:49:10.783882: Client 1\n",
      "2024-05-29 17:49:11.369349: \tlocal_epoch   0 | lr 0.2 | ms/batch 581.47| loss  3.31\n",
      "2024-05-29 17:49:11.904344: \tlocal_epoch   1 | lr 0.2 | ms/batch 535.00| loss  0.75\n",
      "2024-05-29 17:49:11.920361: Client 2\n",
      "2024-05-29 17:49:12.465884: \tlocal_epoch   0 | lr 0.2 | ms/batch 538.50| loss  3.33\n",
      "2024-05-29 17:49:13.002880: \tlocal_epoch   1 | lr 0.2 | ms/batch 537.00| loss  0.70\n",
      "2024-05-29 17:49:13.018878: Client 3\n",
      "2024-05-29 17:49:13.563712: \tlocal_epoch   0 | lr 0.2 | ms/batch 539.83| loss  9.42\n",
      "2024-05-29 17:49:14.102746: \tlocal_epoch   1 | lr 0.2 | ms/batch 539.03| loss  3.10\n",
      "2024-05-29 17:49:14.121739: Client 4\n",
      "2024-05-29 17:49:14.663931: \tlocal_epoch   0 | lr 0.2 | ms/batch 537.22| loss  3.90\n",
      "2024-05-29 17:49:15.201240: \tlocal_epoch   1 | lr 0.2 | ms/batch 537.31| loss  1.12\n",
      "2024-05-29 17:49:15.257207: Aggregate 5 models\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cdist only supports at least 2D tensors, X1 got: 1D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m FLSettings\u001b[38;5;241m.\u001b[39mmalignant_client_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m FLSettings\u001b[38;5;241m.\u001b[39maggregation_function_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKrum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m accuracy, asr \u001b[38;5;241m=\u001b[39m \u001b[43mlearn_federated\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m fl_metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([fl_metrics_df, pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict({\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation Method\u001b[39m\u001b[38;5;124m\"\u001b[39m: [FLSettings\u001b[38;5;241m.\u001b[39maggregation_function_name],\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m: [accuracy],\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Main Task) Accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m })])\n\u001b[0;32m     12\u001b[0m fl_metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([fl_metrics_df, pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict({\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation Method\u001b[39m\u001b[38;5;124m\"\u001b[39m: [FLSettings\u001b[38;5;241m.\u001b[39maggregation_function_name],\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m: [asr],\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttack Success Rate (ASR)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     16\u001b[0m })])\n",
      "Cell \u001b[1;32mIn[53], line 54\u001b[0m, in \u001b[0;36mlearn_federated\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     aggregated_weights \u001b[38;5;241m=\u001b[39m fed_avg(all_trained_weights, global_model\u001b[38;5;241m.\u001b[39mneural_network_state_dict)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m FLSettings\u001b[38;5;241m.\u001b[39maggregation_function_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKrum\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 54\u001b[0m     aggregated_weights \u001b[38;5;241m=\u001b[39m \u001b[43mkrum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_trained_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneural_network_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFLSettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmalignant_client_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid aggregation function was chosen in FLSettings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLSettings\u001b[38;5;241m.\u001b[39maggregation_function_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[55], line 47\u001b[0m, in \u001b[0;36mkrum\u001b[1;34m(all_models, base_model, malignant_client_count, verbose)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Calculate collection distance, the distance from points to points\u001b[39;00m\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m result_state_dict[layer_name]\u001b[38;5;66;03m#.permute(0, 2, 1)\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m cdist \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Find the k+1 nbh of each point\u001b[39;00m\n\u001b[0;32m     50\u001b[0m nbhDist, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(cdist, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, largest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Daan\\Documents\\Projecten\\ru-security-and-privacy-of-machine-learning-23-24\\env\\Lib\\site-packages\\torch\\functional.py:1330\u001b[0m, in \u001b[0;36mcdist\u001b[1;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   1328\u001b[0m         cdist, (x1, x2), x1, x2, p\u001b[38;5;241m=\u001b[39mp, compute_mode\u001b[38;5;241m=\u001b[39mcompute_mode)\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_mm_for_euclid_dist_if_necessary\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compute_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_mm_for_euclid_dist\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mcdist(x1, x2, p, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cdist only supports at least 2D tensors, X1 got: 1D"
     ]
    }
   ],
   "source": [
    "FLSettings.malignant_client_count = 1\n",
    "FLSettings.aggregation_function_name = \"Krum\"\n",
    "\n",
    "accuracy, asr = learn_federated()\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Aggregation Method\": [FLSettings.aggregation_function_name],\n",
    "    \"Score\": [accuracy],\n",
    "    \"Metric\": [\"(Main Task) Accuracy\"]\n",
    "})])\n",
    "\n",
    "fl_metrics_df = pd.concat([fl_metrics_df, pd.DataFrame.from_dict({\n",
    "    \"Aggregation Method\": [FLSettings.aggregation_function_name],\n",
    "    \"Score\": [asr],\n",
    "    \"Metric\": [\"Attack Success Rate (ASR)\"]\n",
    "})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=fl_metrics_df, x=\"Aggregation Method\", y=\"Score\", hue=\"Metric\")\n",
    "\n",
    "display(fl_metrics_df)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Distributed Backdoor Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.a\n",
    "Q: Implement the Distributed Backdoor Attack (DBA). The network\n",
    "of clients is composed of three malicious clients and three benign clients. The\n",
    "three malicious clients will split a red 6 × 6 square trigger vertically into three\n",
    "equal parts. Use the following parameters/settings for your attack:\n",
    "- **Model**: Load the pre-trained ResNet18Light model from the Federated Learning tutorial.\n",
    "- **Poisoning Rate**: Every malicious client should use a poisoning rate of 50% of the local dataset.\n",
    "- **Global Aggregation Rounds**: 5.\n",
    "- **Local Training Epochs**: 2.\n",
    "- **Backdoor Target Class**: 0 (airplane).\n",
    "- **Number Selected Clients Per Round**: 6 (all).\n",
    "- **Aggregation Method**: FedAvg.\n",
    "\n",
    "Plot the final ASR (y-axis) and global (poisoned) model task accuracy (y-axis).\n",
    "Compare your results with your plot from question 1(a). How does DBA perform\n",
    "compared to the previous FL attack setting? Which FL attack setup performs\n",
    "best and why do you think this is the case? Share your conclusions.\n",
    "\n",
    "*Note*: In DBA, during the training phase, the trigger pattern is split between\n",
    "the clients, but in testing time, you should test the attack (i.e., ASR and Model\n",
    "Accuracy) with the complete original trigger and not tear it apart! Once FL\n",
    "training is finished, we assume just one global model in test time and no clients\n",
    "and servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clipping Defense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.a\n",
    "Q: Take exactly the same settings as question 2.1.a but limit it to just 1\n",
    "malicious client. Use the blend attack and at each round let the malicious client\n",
    "apply the scale update with a scaling factor of $\\gamma = \\frac{n}{\\mu}$. Here $n$ is the number of\n",
    "clients and $\\mu$ is the learning rate which is also the number of malicious clients\n",
    "and thus now set to 1. Finally, plot the ASR (y-axis) and global model accuracy\n",
    "(y-axis) for just the “scaling approach” (x-axis). Store these results, as you will\n",
    "re-use them in a new plot for the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.b\n",
    "Q: Enforce an upper boundary for the L2-norms of model updates, restricting the Euclidean distances between the global and the respective local\n",
    "models. The model shall be down-scaled if the L2-norm exceeds the boundary\n",
    "(clipping).\n",
    "\n",
    "A challenge here is determining a suitable clipping boundary: if it is fixed and too\n",
    "low, the aggregated model will be very similar to the global model. Otherwise,\n",
    "if too high, this does not prevent scaling-based attacks.\n",
    "Since the norm values of the models change during the training process and\n",
    "become smaller when the model converges, we need to select the boundary dynamically. For that, compute the Euclidean distance from every model to the\n",
    "aggregated one (from the previous round). Then, get the median, use that as\n",
    "the clipping boundary, and clip all the models to have the same norm.5\n",
    "Use the same setup as in question 2.3.a. This means you also apply the scaling\n",
    "update at each round. Now at each aggregation step, you apply clipping defense\n",
    "using a clipping boundary as explained above. For the final round, report a\n",
    "figure similar to Figure 1, before and after clipping. Also, plot the ASR (y-axis)\n",
    "and global model accuracy (y-axis) and add them to the plot of question 2.3.a\n",
    "with ”clipping defense” below it (x-axis). Compare the results for only using\n",
    "scaling and the case where you apply the defense. Was the defense effective\n",
    "against the attack? Share your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: The best candidate layer to prune is most often the final convolution layer, so conv3. This is because deeper convolution layers most often learn the most features. Early convolution layers mostly learn basic features that are benign, but the deeper a layer is, and especially the more channels it has, the more likely it is that some channels/features are specialized in capturing information about the backdoor. Pruning the final layer would then mean removing channels/features dedicated to the backdoor, reducing the backdoor's effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
