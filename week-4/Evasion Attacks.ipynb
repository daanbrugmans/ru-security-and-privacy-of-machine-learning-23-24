{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db14bfe",
   "metadata": {},
   "source": [
    "# Evasion Attacks\n",
    "\n",
    "In this tutorial you will try out two evasion attacks mentioned during the lecture. The first part of the notebook will guide you through the implementation of the *Fast Gradient Sign Method (FGSM)*. We will show you how to implement it yourself and how you can use an existing library to get the same resutls. The final part of this notebook focuses on implementing *Projected Gradient Descent (PGD)*. You will need to implement it yourself. In both cases we will make use of the MNIST dataset and a simple convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ebbe4",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Lets first import important packages. This includes the package [torchattacks](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html), a PyTorch library that provides adversarial attacks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting and computing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# PyTorch packages\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cross_entropy, softmax\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# This will install torchattacks if not yet present\n",
    "#!pip install torchattacks\n",
    "import torchattacks\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# For Load Bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2aaf85-109a-4493-aeaa-c2de39ddbb09",
   "metadata": {},
   "source": [
    "## Device\n",
    "\n",
    "We also set the device variable so that we can easily switch from using cpu to gpu (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what device we are using\n",
    "use_cuda=True\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ce7b3-9b17-4c63-a224-1a3aaf8eb90a",
   "metadata": {},
   "source": [
    "## Random Seed\n",
    "\n",
    "Execute the code snippet below to set the random seed. This will ensure that you can reproduce results over multiple tries. So anyone who re-runs your code will get the exact same outputs.\n",
    "\n",
    "For example: we will set shuffle to True and so the training loader will randomly shuffle the data over multiple runs. If you make changes to your code because training is not going well, then setting the random seed ensures that you can perform the training with the same samples as in previous tries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca727f-c9ec-4a35-8d7e-42f0ffc88ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this method to be able to reproduce results over multiple tries\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    # GPU operations have a separate seed we also want to set\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "        # We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560187b",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We already introduced the MNIST dataset in a previous tutorial where we trained and tested a MLP and CNN on it. It is an illustrative dataset that is also not to big and so training a new model does not take too much time. We make use of PyTorch's `DataLoader` class to create objects that we can use to sample training and test data using batches of size 128.\n",
    "\n",
    "However, we set the batch size for the test loader to 1. This is uncommon, but it is needed as we will loop over all test samples individual to compute the accuracy of the model when the attack has been applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba413523",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "img_size  = 28\n",
    "channel   = 1\n",
    "num_workers = 0\n",
    "train_size = round((5/6),2)\n",
    "val_size = round(1.0-train_size,2)\n",
    "\n",
    "# A method to ensure reproducibility\n",
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root='./data', transform=transforms.ToTensor(), download=True, train=True)\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [int(len(train_set)*train_size), int(len(train_set)*val_size)])\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=num_workers, pin_memory=True, worker_init_fn=_init_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=_init_fn)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='./data', transform=transforms.ToTensor(), download=True, train=False)\n",
    "test_loader = DataLoader(test_set,  batch_size=1, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e7717",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "Here we provide a basic CNN network that we will train on the MNIST dataset and then attack using FGSM and PGD. Feel free to alter the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f8d56-d136-4f9f-917a-4201023fc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 128, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(128, 224, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.drop2 = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.fc3 = nn.Linear(224*4*4, 64)\n",
    "        self.drop3 = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.drop4 = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.fc5 = nn.Linear(32, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.pool1(F.relu(self.conv1(x))))\n",
    "        x = self.drop2(self.pool2(F.relu(self.conv2(x))))\n",
    "        x = x.view(-1,224*4*4)\n",
    "        x = self.drop3(F.relu(self.fc3(x)))\n",
    "        x = self.drop4(F.relu(self.fc4(x)))\n",
    "        x = self.softmax(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a56e32a",
   "metadata": {},
   "source": [
    "We also define an optimizer and loss function with hyper parameter settings for training. Again feel free to make changes to these settings, but for the purpose of learning to work with FGSM and PGD you can use these pre-defined settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6246ff-a4e2-4f7f-861d-98d858ad1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(),lr=1.0)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0bbea",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a8a17",
   "metadata": {},
   "source": [
    "To train our own model we use some of the methods we provided in the previous tutorial on model training. \n",
    "Below you find the following methods:\n",
    "\n",
    "- `accuracy(predictions,labels)`: Takes the two tensors `predictions` and `labels` as input and computes the total number of correct predictions divided by the total number of predictions. This Float value is returned.\n",
    "- `log_training(batch_idx, running_loss, running_acc)`: Takes Integer `batch_idx` which specifies the batch index, Float `running_loss` which represents the loss at that moment of the training, Float `running_acc` which represents the accuracy at that moment of the training. It simply prints these values.\n",
    "- `training_step(model, batch, criterion)`: Takes PyTorch `model`, Tuple `batch` which contains image(s) and label(s), Torch Loss Function `criterion`. This method uses these values to generate predictions, calculate the loss and also the accuracy. It then returns both Float loss and  Float accuracy.\n",
    "- `validation_step(model, batch, criterion)`: Takes PyTorch `model`, Tuple `batch` which contains image(s) and label(s), Torch Loss Function `criterion`. This method uses these values to generate predictions, calculate the loss and also the accuracy. It then returns both Float loss and  Float accuracy inside a Dict.\n",
    "- `validate(model, val_loader, criterion)`: Takes PyTorch `model`, PyTorch DataLoader `val_loader`, Torch Loss Function `criterion`. This method goes over all batches in the val_loader and performs the validation_step. After this it computes the total epoch loss and accuracy by taking the mean over all batch values. These both Float values are returned inside a Dict.\n",
    "- `epoch_end(result)`: Takes Dict `result` which holds the epoch loss and epoch accuracy values. Both values are simply printed.\n",
    "- `train(model, model_name, criterion, optimizer, train_loader, val_loader, num_epochs=10)`: Takes PyTorch `model`, String `model_name`, PyTorch Loss function `criterion`, PyTorch optimizer function `optimizer`, PyTorch DataLoader `train_loader`, PyTorch DataLoader `val_loader`, Integer `num_epochs`. Performs training of model. Model name is used to save the trained model. Loops over all batches in train loader and val loader. Num epochs determines for how many epochs, default is set to 10. Returns `history` which contains all epochs losses and accuracies.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f8bb3-f721-4eb5-b405-d2a65393842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to compute accuracy\n",
    "def accuracy(predictions,labels):\n",
    "    _, preds = torch.max(predictions, dim=1)\n",
    "    return (torch.tensor(torch.sum(preds == labels).item() / len(preds)))\n",
    "\n",
    "# Method to log training / running loss and accuracy\n",
    "def log_training(batch_idx, running_loss, running_acc):\n",
    "    print(f\"Batch: {batch_idx}, Running Loss: {running_loss / (batch_idx + 1):.2f}, Running Accuracy: {running_acc:.2f}\")\n",
    "\n",
    "def training_step(model, batch, criterion):\n",
    "    # Prepare batch data\n",
    "    images, labels = batch\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # Generate predictions\n",
    "    predictions = model(images)\n",
    "    # Calculate loss\n",
    "    loss = criterion(predictions, labels)\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy(predictions, labels)\n",
    "    return loss, acc\n",
    "\n",
    "def validation_step(model, batch, criterion):\n",
    "    # Prepare batch data\n",
    "    images, labels = batch\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # Generate predictions\n",
    "    predictions = model(images)\n",
    "    # Calculate loss\n",
    "    loss = criterion(predictions, labels)\n",
    "    # Calculate Accuracy\n",
    "    acc = accuracy(predictions, labels)\n",
    "    return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = [validation_step(model, batch, criterion) for batch in val_loader]\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "# Method to log epoch loss and accuracy\n",
    "def epoch_end(result):\n",
    "    print(f\"val_loss: {result['val_loss']:.2f}, val_acc: {result['val_acc']:.2f}\\n\")\n",
    "\n",
    "def train(model, model_name, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: \", epoch+1)\n",
    "        running_loss = 0\n",
    "        # Training Phase\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            # Calculate Loss\n",
    "            loss, running_acc = training_step(model, batch, criterion)\n",
    "            # Compute Gradients\n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            # Reset Gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # running loss and accuracy\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 50 == 0 and batch_idx != 0:\n",
    "                log_training(batch_idx, running_loss, running_acc)\n",
    "\n",
    "        # Validation Phase\n",
    "        result = validate(model, val_loader, criterion)\n",
    "        epoch_end(result)\n",
    "        history.append(result)\n",
    "\n",
    "    # Save checkpoint file\n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a91af6b",
   "metadata": {},
   "source": [
    "Now train the model for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e0e3e-257b-44ca-89a2-b7278b940199",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = train(model,\"cnn_model\",criterion,optimizer,train_loader,val_loader,num_epochs=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b92f93f",
   "metadata": {},
   "source": [
    "## FGSM\n",
    "\n",
    "Now that we constructed and trained a basic CNN we will start with our first evasion attack: FGSM. Below you see the panda example also shared during the lecture. Here we have $x$, which is the original image, and we add $\\epsilon \\cdot sign(\\bigtriangledown_x \\mathcal{J}(\\theta,x, y))$ to get the adversarial image $x'$. Where $y$ is the ground truth label for $x$, $\\theta$ represents the model parameters, and $\\mathcal{J}(\\theta,x, y)$ is the loss that is used to train the network. To calculate $\\bigtriangledown_x \\mathcal{J}(\\theta,x, y)$, the attack backpropagates the gradient back to the input data. Then it uses $\\epsilon$ to adjust the input data by a small step in the direction (i.e. $sign(\\bigtriangledown_x \\mathcal{J}(\\theta,x, y))$) that maximizes the loss. All together:\n",
    "\n",
    "$$x' = x + \\epsilon \\cdot sign(\\bigtriangledown_x \\mathcal{J}(\\theta,x, y))$$\n",
    "\n",
    "![FGSM](images/fgsm_panda_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68732da",
   "metadata": {},
   "source": [
    "### Epsilon\n",
    "\n",
    "Just like in the official [PyTorch FGSM tutorial](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html), we define a list of epsilon values to use during the attack. It includes 0 to represent the model performance on the original test set and we build up to higher values to see what effect this has on the accuracy and on the images. The idea is that the larger the epsilon, the more noticeable the perturbations but the more effective the attack in terms of degrading model accuracy. Since the data range here is $[0,1]$, no epsilon value should exceed 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3111853",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d72fa",
   "metadata": {},
   "source": [
    "### Visualization perturbation FGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fc280",
   "metadata": {},
   "source": [
    "Let's take a batch of images from MNIST test set and plot them before we use FGSM on them and after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images,labels):\n",
    "    np_images = images.detach().cpu().numpy()\n",
    "\n",
    "    # making sure we can view the images\n",
    "    np_images = np_images*255\n",
    "    np_images = [image.astype(np.uint8).reshape((28, 28, 1)) for image in np_images]\n",
    "\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(25, 4))\n",
    "    for idx in np.arange(20):\n",
    "        ax = fig.add_subplot(2, 20//2, idx+1, xticks=[], yticks=[])\n",
    "        ax.imshow(np_images[idx], cmap='gray')\n",
    "        # print out the correct label for each image\n",
    "        # .item() gets the value contained in a Tensor\n",
    "        ax.set_title(str(labels[idx].item()))\n",
    "        \n",
    "def plot_image(image,label):\n",
    "    figure = plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(image[0].cpu(), cmap='gray')\n",
    "    plt.title(str(label.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bef2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of training images and labels\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "plot_images(images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccef2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(images[0],labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fbc967",
   "metadata": {},
   "source": [
    "Now lets compute the adverserial images for this batch using FGSM. \n",
    "\n",
    "Below we provide you a `FGSM` class which you can use to create a FGSM attack object. The object can be created providing a (trained) model, epsilon value between 0.0 and 1.0 (default set to 0.3), loss function (default set to Cross Entropy) and the device (default set to cpu). \n",
    "\n",
    "The `forward()` method of the `FGSM` class can be used to create adversarial images. It takes in images and corresponding labels. It then uses the trained model to generate predictions and compute the loss. Using [`torch.autograd.grad()`](https://pytorch.org/docs/stable/generated/torch.autograd.grad.html) it computes the sum of gradients of the predictions with respect to the inputs. Using this sum of gradients and the epsilon value we can then create adversarial image of the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63894725",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGSM(nn.Module):\n",
    "    \n",
    "    def __init__(self, model, eps=0.3, criterion=nn.CrossEntropyLoss(),device='cpu'):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.eps = eps\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, images, labels):\n",
    "        # Prepare data\n",
    "        images = images.clone().detach().to(self.device)\n",
    "        labels = labels.clone().detach().to(self.device)\n",
    "        # Specify that the gradients need to be computed\n",
    "        images.requires_grad = True\n",
    "        # Generate predictions\n",
    "        predictions = self.model(images)\n",
    "        # Compute Loss\n",
    "        loss = self.criterion(predictions,labels)\n",
    "        # Calculate the derivative of the loss w.r.t. the original image\n",
    "        grad = torch.autograd.grad(loss, images, retain_graph=False, create_graph=False)[0]\n",
    "        # Compute the adversarial images\n",
    "        adv_images = images + self.eps*grad.sign()\n",
    "        adv_images = torch.clamp(adv_images, min=0, max=1).detach()\n",
    "        return adv_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720b7494-fa30-459d-9e42-62b439aec83c",
   "metadata": {},
   "source": [
    "Execute the code cell below to create a FGSM attack object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ce2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = FGSM(model=model,eps=0.3,criterion=criterion,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_images = attack(images,labels)\n",
    "plot_images(adv_images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(adv_images[2],labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d0fb6",
   "metadata": {},
   "source": [
    "As you can see from the last two plots is that using $\\epsilon = 0.3$ causes very noticeable perturbations. The changes to the original images can be spotted quite easily. Lets now check what is the effect on the performance of the used model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb1f14",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0a338",
   "metadata": {},
   "source": [
    "For the purpose of checking the effectiveness of the FGSM attack on the performance of our model we provide you with the `test` method below. This method takes in the `model`, `test_loader` and `epsilon` value. This way we can try out different epsilon values to see how this affects the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_perturbed_image(image, epsilon):\n",
    "    # Collect gradient\n",
    "    image_grad = image.grad.data\n",
    "        \n",
    "    # Collect the element-wise sign of the gradient\n",
    "    sign_image_grad = image_grad.sign()\n",
    "        \n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon * sign_image_grad\n",
    "        \n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "    return perturbed_image\n",
    "\n",
    "def save_example(adv_examples, perturbed_image, init_pred, final_pred):\n",
    "    adv_ex = perturbed_image.squeeze().detach().cpu().numpy()\n",
    "    adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))\n",
    "\n",
    "def attack_test(model, criterion, device, test_loader, epsilon):\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    \n",
    "    # Loop over all samples in test set\n",
    "    for image, label in test_loader:\n",
    "        \n",
    "        # Send the data and label to the device\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        \n",
    "        # Set requires_grad attribute to True. Important for Attack\n",
    "        image.requires_grad = True\n",
    "        \n",
    "        # Forward pass the data through the model\n",
    "        prediction = model(image)\n",
    "        \n",
    "        # Get the index of the max log-probability\n",
    "        _, init_pred = prediction.max(1, keepdim=True)\n",
    "        \n",
    "        # If the initial prediction is wrong, don't bother attacking, just move on\n",
    "        if init_pred.item() != label.item():\n",
    "            continue\n",
    "            \n",
    "        # Calculate the loss\n",
    "        loss = criterion(prediction, label)\n",
    "        \n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Compute pertrubed image\n",
    "        perturbed_image = create_perturbed_image(image, epsilon)\n",
    "        \n",
    "        # Re-classify the perturbed image\n",
    "        new_prediction = model(perturbed_image)\n",
    "        \n",
    "         # Get the index of the max log-probability\n",
    "        _, final_pred = new_prediction.max(1, keepdim=True)\n",
    "        \n",
    "        # Check for success\n",
    "        if final_pred.item() == label.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                save_example(adv_examples, perturbed_image, init_pred, final_pred)\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                save_example(adv_examples, perturbed_image, init_pred, final_pred)\n",
    "    \n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = attack_test(model, criterion, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6e89f",
   "metadata": {},
   "source": [
    "### Accuracy vs Epsilon\n",
    "\n",
    "Like we mentioned earlier as the epsilon increases we expect the test accuracy to decrease. The reason is that with a larger epsilon we take a larger step in the direction that will maximize the loss. Notice the trend in the curve is not linear even though the epsilon values are linearly spaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac497897",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b7113",
   "metadata": {},
   "source": [
    "While a higher epsilon might decrease the accuracy, the plots below also show that the perturbations become more easily perceptible. So an attacker should consider a tradeoff between accuracy degredation and perceptibility of the perturbations. The plots below show examples of successfull adversarial examples at each epsilon value. Each row of the plot shows a different epsilon value. The first row is the $\\epsilon = 0$ examples which represent the original \"clean\" images with no perturbation. The title of each image shows the \"original classification -> adversarial classification\". Notice, the perturbations start to become evidant from around $\\epsilon = 0.15$ and are quite evident at $\\epsilon = 0.3$. However, in all cases humans are still capable of identifying the correct class despite the added noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several examples of adversarial samples at each epsilon\n",
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263c1b4f-c099-44fa-96c4-a6319fd5d713",
   "metadata": {},
   "source": [
    "### Attack Evaluation\n",
    "\n",
    "To evaluate the success of your evasion attack you could measure the model's accuracy. First you test your model using clean samples. Then you test your model using your evasion attack and a specific epsilon value. The drop in accuracy rate is the measure of success of your attack. The code snippet below shows you how this is done. We can reuse the `attack_test()` method from earlier using `epsilon=0` to test the clean model on only clean samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa097bc-b311-4c62-8790-00549a39f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean test\n",
    "clean_acc, _ = attack_test(model, criterion, device, test_loader, epsilon=0.0)\n",
    "\n",
    "# attack test\n",
    "attack_acc, _ = attack_test(model, criterion, device, test_loader,epsilon=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6fd8f-a64a-4eca-a071-6a20d6dded1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_drop = round(attack_acc-clean_acc,2)\n",
    "print(f\"Accuracy Drop: {acc_drop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626c6ca-3f59-4910-8279-10ccc98265bd",
   "metadata": {},
   "source": [
    "You can also use the `test()` method below to test the accuracy of your model without attack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ffca8-4c92-4a38-978e-cf9764fa50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, optimizer, test_loader):\n",
    "    # Execute Testing\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in tqdm(test_loader):\n",
    "            # Prepare batch data\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Generate predictions\n",
    "            predictions = model(images)\n",
    "            # Calculate loss\n",
    "            batch_test_loss = criterion(predictions, labels)\n",
    "            # Calculate accuracy\n",
    "            batch_test_acc = accuracy(predictions, labels)\n",
    "            # Store batch results\n",
    "            test_loss.append(batch_test_loss)\n",
    "            test_acc.append(batch_test_acc)\n",
    "    \n",
    "    # Display Results\n",
    "    print(\"Test Loss: \", round(torch.stack(test_loss).mean().item(),2))\n",
    "    print(\"Test Accuracy: \", round(torch.stack(test_acc).mean().item()*100.0,2))\n",
    "    return round(torch.stack(test_acc).mean().item(),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89883c00-2a54-4f23-af55-fb53564add1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_acc = test(model, criterion, optimizer, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687856d7-0fb0-4baa-9e3a-4b9fc5cabade",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_drop = round(attack_acc-clean_acc,2)\n",
    "print(f\"Accuracy Drop: {acc_drop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b976d8b-5adb-49ff-af25-1872366cb2b2",
   "metadata": {},
   "source": [
    "If you would do this for all epsilon you could then plot the accuracy drops in a bar plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb84567-97c5-4131-bc67-1f7c09614989",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_drops = [round(x - accuracies[0],4) for x in accuracies[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad95131-31e6-4b69-902c-f1eae42cb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(range(len(acc_drops)), acc_drops, color='skyblue')\n",
    "\n",
    "# Adding the text inside the bars for each value\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval - 0.03, round(yval, 4), ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Epsilon Value')\n",
    "plt.ylabel('Accuracy Drop')\n",
    "plt.title('Bar Plot Evasion Attack Accuracy Drop')\n",
    "plt.xticks(range(len(acc_drops)), [str(eps) for eps in epsilons[1:]])  # Set x-ticks to be the indices\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2cb61",
   "metadata": {},
   "source": [
    "### Torchattacks\n",
    "\n",
    "Instead of implementing the FGSM attack yourself, you can also make use of PyTorch `torchattack` library that includes many predefined attacks. We will show you that you will get the same result using our earlier implementation of the FGSM attack and the `torchattack` version. First we define a `test` method to show the accuracy of the model using the original images and then we define a `adv_test` method to show the accuracy using FGSM adversarial images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b20f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    print('\\n\\n[Plain/Test] Under Testing ... Please Wait')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_idx, (images, labels) in enumerate(tqdm(test_loader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Evaluation\n",
    "            predictions = model(images).detach()\n",
    "\n",
    "            # Test\n",
    "            _, predicted = torch.max(predictions, dim=1)\n",
    "            total += labels.numel()\n",
    "            correct += (predicted == labels).sum().item() \n",
    "\n",
    "\n",
    "        print('[Plain/Test] Acc: {:.3f}'.format(100.*correct / total))\n",
    "    return 100.*correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868436df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_test(attack, model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "    print('\\n\\n[Plain/Test] Under Testing ... Please Wait')\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(test_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # dataloader parsing and generate adversarial examples\n",
    "        adv_inputs = attack(images, labels)\n",
    "        # Evaluation\n",
    "        predictions = model(adv_inputs).detach()\n",
    "\n",
    "        # Test\n",
    "        _, predicted = torch.max(predictions, dim=1)\n",
    "        total += labels.numel()\n",
    "        correct += (predicted == labels).sum().item() \n",
    "\n",
    "        \n",
    "    print('[Plain/Test] Acc: {:.3f}'.format(100.*correct / total))\n",
    "    return 100.*correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbea799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_test(attack,model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = torchattacks.FGSM(model, eps=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26281c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv_test(attack,model,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef32c1a6",
   "metadata": {},
   "source": [
    "As you can see both lower the performance of our model to the same accuracy and with the `torchattacks` library you only need to provide a pre-trained model and an epsilon value to define the FGSM attack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa41243",
   "metadata": {},
   "source": [
    "## PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deecb59",
   "metadata": {},
   "source": [
    "Now as an exercise you will implement the PGD attack yourself. Complete the code below using information you can find in this notebook, from the lecture slides and in other sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb608a2",
   "metadata": {},
   "source": [
    "PGD in the paper 'Towards Deep Learning Models Resistant to Adversarial Attacks'\n",
    "    [https://arxiv.org/abs/1706.06083](https://arxiv.org/abs/1706.06083)\n",
    "\n",
    "Distance Measure : $\\ell_\\infty$\n",
    "\n",
    "Arguments:\n",
    "- model (nn.Module): model to attack.\n",
    "- eps (float): maximum perturbation. (Default: 0.3)\n",
    "- alpha (float): step size. (Default: 2/255)\n",
    "- steps (int): number of steps. (Default: 10)\n",
    "- random_start (bool): using random initialization of delta. (Default: True)\n",
    "\n",
    "Shapes:\n",
    "- images: $(N, C, H, W)$ where $N$ = number of batches, $C$ = number of channels, $H$ = height and $W$ = width. It must have a range $[0, 1]$.\n",
    "- labels: $(N)$ where each value $y_i$ is $0 \\leq y_i \\leq$ number of labels.\n",
    "- output: $(N, C, H, W)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c46c2e",
   "metadata": {},
   "source": [
    "$$x_{t+1} = Clip_{x+S} (x_{t} + \\alpha sign(\\bigtriangledown_x \\mathcal{J}_{\\theta}(x, l)))$$\n",
    "\n",
    "*Note:* this formula is taken from the original paper where they use $x$ instead of $x_{t}$ inside $sign(\\cdot)$. This is a generic representation.\n",
    "\n",
    "For your implementation below you should consider:\n",
    "\n",
    "\n",
    "$$x_{t+1} = Clip_{x+S} (x_{t} + \\alpha sign(\\bigtriangledown_x \\mathcal{J}_{\\theta}(x_{t}, l)))$$\n",
    "\n",
    "Where $Clip_{x+S}$, means that you project $x_{t}$ back when it went out of the limitation ($x+S$). \n",
    "\n",
    "Consider the following:\n",
    "\n",
    "1) When you update the adversarial images inside the loop with grad you do not want the adversarial images to be too different, so PGD projects it by back so that the perturbation (adv_image - original_image) should be in the range of $[-\\epsilon,\\epsilon]$.\n",
    "2) After you add this perturbation (the variable delta in PGD), you want to make sure it is a real image. So you should project it back such that the image is in range $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PGD(nn.Module):\n",
    "    \n",
    "    def __init__(self, model, eps=8/255,\n",
    "                 alpha=2/255, steps=10, random_start=True,loss=nn.CrossEntropyLoss(),device='cpu'):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "        self.steps = steps\n",
    "        self.random_start = random_start\n",
    "        self.loss = loss\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        images = images.clone().detach().to(self.device)\n",
    "        labels = labels.clone().detach().to(self.device)\n",
    "\n",
    "        adv_images = images.clone().detach().to(self.device)\n",
    "\n",
    "        if self.random_start:\n",
    "            # Starting at a uniformly random point\n",
    "            adv_images = adv_images + torch.empty_like(adv_images).uniform_(-self.eps, self.eps)\n",
    "            adv_images = torch.clamp(adv_images, min=0, max=1).detach()\n",
    "            \n",
    "\n",
    "        # Implementation of PGD\n",
    "        \n",
    "        # PGD is a multi-step version of FGSM\n",
    "        for _ in range(self.steps):\n",
    "            # Prepare images and labels\n",
    "            \n",
    "            # Generate predictions\n",
    "\n",
    "            # Calculate loss\n",
    "\n",
    "            # Update adversarial images\n",
    "            \n",
    "            # Project x_t back with torch.clamp\n",
    "\n",
    "\n",
    "        return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc36c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a PGD attack\n",
    "attack = PGD(model=model,eps=0.3,alpha=2/255,steps=10,random_start=False,device=device)\n",
    "\n",
    "# Test the PGD attack\n",
    "adv_test(attack,model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a torchattacks PGD attack\n",
    "attack_torch = torchattacks.PGD(model=model, eps=0.3, alpha=2/255, steps=10, random_start=False)\n",
    "\n",
    "# Test the torchattacks PGD attack for comparison\n",
    "adv_test(attack_torch,model,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
