{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0049178",
   "metadata": {},
   "source": [
    "# CIFAR-10\n",
    "\n",
    "The goal of this notebook is for you to implement a MLP and CNN network just like we did for the MNIST dataset. However, this time you will need to implement certain parts of code yourself. Try to use the information from the MNIST notebook to figure out how you could implement these parts and test these networks on the CIFAR-10 dataset. More information on this dataset will follow.\n",
    "\n",
    "At the end of this notebook you will construct a submission file for the CIFAR-10 focused *Playground Prediction Competition* [CIFAR-10 - Object Recognition in Images](https://www.kaggle.com/competitions/cifar-10/overview). We included this part in the notebook as we think it is a fun way to learn to use PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d946102",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First lets import the necessary packages.\n",
    "\n",
    "You will need to import PyTorch and some additional packages to preprocess and visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a674c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b9840",
   "metadata": {},
   "source": [
    "## GPU\n",
    "\n",
    "Now write the code to make use of GPU if it is available or otherwise use a CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb4aee",
   "metadata": {},
   "source": [
    "Also add code to set the seed if GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa037da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b226d",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset of tiny images. The original CIFAR-10 dataset consists of 60.000 32x32 colour images in 10 classes, with 6.000 images per class. There are 50.000 training images and 10.000 test images. The 10 classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. The task is also very straightforward: you will train a neural network to correctly identify the class from the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70996df",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "On the [data](https://www.kaggle.com/competitions/cifar-10/data) page of the Kaggle competition for CIFAR-10 you can download all the files. Locate the *Download All* button in the bottom right corner of the page and download the zip file to your machine. Unzip it and also the test and train folders. \n",
    "\n",
    "Then load the files using the following piece of code. This will also use pip to install opencv-python as you probably did not yet install this package and we need it to load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ab36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "cifar10_path = \"./cifar-10/\"\n",
    "train_images_path = cifar10_path + \"train/\"\n",
    "test_images_path = cifar10_path + \"test/\"\n",
    "    \n",
    "# Since the folders only contain Images, the size of the datasets is the number of files in it's folder\n",
    "num_of_train_images = len(glob.glob(train_images_path+\"*\"))\n",
    "num_of_test_images = len(glob.glob(test_images_path+\"*\"))\n",
    "\n",
    "# Load the training labels\n",
    "train_labels = pd.read_csv(cifar10_path+\"trainLabels.csv\")\n",
    "classes = list(set(list(train_labels.label)))\n",
    "num_classes=len(classes)\n",
    "labels_dict =  {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "labels_dict_reversed = {'airplane':0, 'automobile':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "train_labels['category'] = train_labels.label.map(labels_dict_reversed)\n",
    "\n",
    "# Let's create an array from the images\n",
    "train_images = [[]]*num_of_train_images\n",
    "for dir_name, _, filenames in os.walk(train_images_path):\n",
    "    for filename in tqdm.tqdm(filenames):\n",
    "        image_index = int(filename.split(\".\")[0])-1\n",
    "        img = cv2.imread(os.path.join(dir_name,filename))\n",
    "        # Add the image to the array\n",
    "        train_images[image_index] = img\n",
    "train_images = np.asarray(train_images, dtype=float)\n",
    "\n",
    "test_images = [[]]*num_of_test_images\n",
    "for dir_name, _, filenames in os.walk(test_images_path):\n",
    "    for filename in tqdm.tqdm(filenames):\n",
    "        image_index = int(filename.split(\".\")[0])-1\n",
    "        img = cv2.imread(os.path.join(dir_name,filename))\n",
    "        # Add the image to the dataset\n",
    "        test_images[image_index] = img\n",
    "test_images = np.asarray(test_images, dtype=float)\n",
    "\n",
    "# Let's check if the training set has been loaded properly\n",
    "print('train_images.shape:\\n', train_images.shape)\n",
    "print('test_images.shape:\\n', test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870da21",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "\n",
    "#### Splitting features and target variables\n",
    "\n",
    "This time the labels are already split from the features and so we provide you with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88615301",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_images\n",
    "y = train_labels.category.values\n",
    "\n",
    "print(\"X.shape: \", X.shape, \"X.type: \", type(X))\n",
    "print(\"y.shape: \", y.shape, \"y.type: \", type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d34d0",
   "metadata": {},
   "source": [
    "#### Split the data into train and test sets\n",
    "\n",
    "\n",
    "Now try to split the training data into a smaller training set and an additional test set that can be used for validation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06afd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7acadc",
   "metadata": {},
   "source": [
    "## Visualizing Data\n",
    "\n",
    "An important step in an image classification task is to look at the data, make sure it is loaded correctly and then make any initial observations about patterns in that data.\n",
    "\n",
    "Make use of the `matplotlib` library to plot the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0aa4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of training images\n",
    "images, labels = ...\n",
    "\n",
    "# making sure we can view the images\n",
    "images = ...\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "# Write Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f04da",
   "metadata": {},
   "source": [
    "#### Plotting just one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = X_train[3], y_train[3]\n",
    "\n",
    "img = img.astype(np.uint8).reshape((32, 32, 3))\n",
    "\n",
    "plt.title(labels_dict[label])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2598df",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "### Rescaling values\n",
    "\n",
    "The pixel values of the original dataset are in the range of (0,255). For a neural network to be efficient, we will rescale these values to (0,1). All the values will be rescaled to be between 0 and 1. \n",
    "\n",
    "Rescale your training and validation/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe80952",
   "metadata": {},
   "source": [
    "### Torch Tensors\n",
    "\n",
    "PyTorch works with tensors and thus we will need to convert the data. Convert the rescaled to Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c298cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73a73b",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "\n",
    "Next use the PyTorch Dataset and DataLoader modules to create custom datasets and dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf66cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here\n",
    "\n",
    "train = ...\n",
    "test = ...\n",
    "\n",
    "batch = ...\n",
    "\n",
    "train_loader = ...\n",
    "test_loader = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8686db3",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data\n",
    "\n",
    "Here we show how to visualize a batch of training data using the DataLoader class. We need to transform our data a bit as we did some preprocessing in the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff604f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = ...\n",
    "images, labels = ...\n",
    "\n",
    "# making sure we can view the images\n",
    "images = ...\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "# Write Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e245738d",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466aa4f",
   "metadata": {},
   "source": [
    "### Define Multilayer Perceptron Architecture\n",
    "\n",
    "Now try to construct your own multilayer perceptron network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here\n",
    "mlp_model = ...\n",
    "print(mlp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2506fa",
   "metadata": {},
   "source": [
    "### Define Convolutional Neural Network Architecture\n",
    "\n",
    "Again, try to construct your own CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here\n",
    "cnn_model = ...\n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a15b6",
   "metadata": {},
   "source": [
    "### Define Loss Function\n",
    "\n",
    "Decide on a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here\n",
    "criterion = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d6a59",
   "metadata": {},
   "source": [
    "### Define Optimizer\n",
    "\n",
    "Pick an optimizer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here\n",
    "mlp_optimizer = ...\n",
    "cnn_optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d95a481",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "\n",
    "Next, write code that you can use to train your models. It should take the model, loss function and optimizer and train your model for a certain amount of epochs. Try to keep track of the loss so that you can plot the training and validation/test loss after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e44dd",
   "metadata": {},
   "source": [
    "## Test Network\n",
    "\n",
    "To be able to make a submission for the CIFAR-10 competition on Kaggle you can use the following piece of code. It is slightly different from the MNIST notebook. Mostly because the test set from Kaggle is a bit large which is why we go over the test samples in batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f135f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing(model):\n",
    "\n",
    "    low = 0\n",
    "    batch = 1000\n",
    "    submission = [['id', 'label']]\n",
    "    image_id = 1\n",
    "    for i in tqdm.tqdm(range(300)):\n",
    "        high = batch*(i+1)\n",
    "        finalTest = test_images[low:high]\n",
    "        finalTest = torch.from_numpy(finalTest)\n",
    "\n",
    "        temp = np.zeros(finalTest.shape)\n",
    "        temp = torch.from_numpy(temp)\n",
    "\n",
    "        data = torch.utils.data.TensorDataset(finalTest, temp)\n",
    "\n",
    "        submissionLoader = torch.utils.data.DataLoader(data, batch_size = 100, shuffle = False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, _ in submissionLoader:\n",
    "                images = (images.view(-1,3,32,32)).type(torch.DoubleTensor)\n",
    "                log_ps = model(images.type(torch.FloatTensor).to(device))\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim = 1)\n",
    "\n",
    "                for prediction in top_class:\n",
    "                    submission.append([image_id, labels_dict[prediction.item()]])\n",
    "                    image_id += 1\n",
    "                    \n",
    "        low = high\n",
    "                    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb673b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_submission = model_testing(mlp_model)\n",
    "cnn_submission = model_testing(cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8123b91",
   "metadata": {},
   "source": [
    "## Make Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd6d9b",
   "metadata": {},
   "source": [
    "Now if you want you can use the code below to create submission files for the Kaggle competition [CIFAR-10 - Object Recognition in Images](https://www.kaggle.com/competitions/cifar-10/overview). Login or create an account at Kaggle and head over to the competition page where you can submit the files created below. You will get a score on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52503aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(submission,filename):\n",
    "    pytorchSubmission = pd.DataFrame(submission)\n",
    "    pytorchSubmission.columns = pytorchSubmission.iloc[0]\n",
    "    pytorchSubmission = pytorchSubmission.drop(0, axis = 0)\n",
    "\n",
    "    pytorchSubmission.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab17f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission_file(mlp_submission,\"cifar10_mlp_submission.csv\")\n",
    "create_submission_file(cnn_submission,\"cifar10_cnn_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
